{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51feaca9-a72d-401d-a59f-5adec9336ca0",
   "metadata": {},
   "source": [
    "### Produce DH matrix on the fly using Numba (not requiring D and H ahead of time)\n",
    "\n",
    "Based on previous experimentation, producing D and H separately and performing matrix multiplication of the two to produce DH is technically fast, but is memory intensive due to how H scales with the desired high resolution image size and how much of the blur kernel is needed per row of H. I attempted to produce DH manually by first creating a stacked blur kernel, flattening it, and striding each 'row' of the kernel over each row of H. This works, but is computationally slow as I had to use a standard for loop to process each row of DH. Threading in python is not great... there are ways to do it but they dont play nicely with other libraries. In my case, the Scipy sparse matrices are not recognised by libraries such as Numba. Furthermore, the Scipy sparse matrices that allow insertion at sliced indices are dog slow when inserting (i.e., dictionary of keys (dok) and list of lists lil).\n",
    "\n",
    "My next approach is to produce DH directly with the help of Numba, where I intend to produce three numpy arrays representing the rows/cols/vals of a Scipy sparse coordinate matrix (coo), where X(row,col) -> val. Numba can atleast understand what numpy arrays are so I should be able to populate the three arrays in parallel and use the three arrays to produce one coo sparse matrix of DH.\n",
    "\n",
    "Tasks to perform:\n",
    "- [x] First confirm whether Numba will populate three small arrays in parallel to produce the coo matrix, a small toy example is sufficient...\n",
    "- [x] Extend the system to accomodate the stacked blur kernel, including strided kernel rows (the matrix will have redundant data present but thats okay for now)\n",
    "- [x] Then extend the system to perform trimming at the edges where kernel entries are out of bounds of the DH matrix\n",
    "- [x] There is an outstanding issue where the kernel_offset val needs to dynamically change depending on high/low res and the dimension of stacked kernel... consider using excel to inspect different configurations to see if a pattern can be found\n",
    "- [ ] Seems to be a slight disagreement between dh vs d@h, looks like a precision issue so double check precisions across the system\n",
    "- [ ] Producing the coo matrix from row/col/val arrays is thrashing memory at higher low/high resolutions and blur kernel sizes. This appears to be because the coo_matrix constructor internally creates a copy of row/col/val buffers instead of simply referencing the provided ones - what a crap solution... Consider performing batching instead and accumulating coo_matrices over time (say low_res_dim // low_res_dim*^2)\n",
    "- [ ] Adding to above, consider changing the func to produce a csr or bsr matrix instead of coo arrays. This will save on both memory ahead of time, and should avoid the memory and runtime requirements needed to change format.\n",
    "- [ ] Seems like its faster to just use numpy instead of any numba features (njit, parallel, etc.). Why is this...\n",
    "\n",
    "Notes:\n",
    "* The number of entries over each row of DH can be different in length, so there will need to be a 'double sweep' approach which first calculates how many entries will be in one row into a sort of row lookup table. This is needed as each individual thread in Numba will need to know how much of the row/col/val arrays it can touch. We can assume that one row will be one thread, so we can use the row indices to determine where to read from the lookup table. The assumption is that the indices of row/col/val arrays touched by one thread is based on lookup(thread_id, thread_id + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf113e7-ae8a-41c7-b6cf-ad2d6ad16388",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from numba import njit, prange\n",
    "from linear_system_super_resolution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b08b1c7-8f30-4461-aee5-ff27e860ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dh_matrix_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%file dh_matrix_analysis.py\n",
    "\n",
    "from numba import njit, prange\n",
    "from linear_system_super_resolution import *\n",
    "\n",
    "### ===================================================================================================================\n",
    "### Full approach\n",
    "### ===================================================================================================================\n",
    "\n",
    "def generate_dh_matrix(kernel, high_res_dim, downsample):\n",
    "    \n",
    "    low_res_dim = high_res_dim // downsample\n",
    "    \n",
    "    # %lprun -f calculate_d_origins d_origins = calculate_d_origins(high_res_dim, downsample)\n",
    "    d_origins = calculate_d_origins(high_res_dim, downsample)\n",
    "    \n",
    "    # %lprun -f produce_stacked_kernel stacked_kernel = produce_stacked_kernel(kernel, downsample)\n",
    "    stacked_kernel = produce_stacked_kernel(kernel, downsample)\n",
    "    # show_image(stacked_kernel, \"Stacked\")\n",
    "    \n",
    "    # Fill in entries for sparse DH matrix\n",
    "    # %lprun -f populate_dh_buffers row_buffer, col_buffer, val_buffer = populate_dh_buffers(d_origins, stacked_kernel, high_res_dim // downsample, high_res_dim, kernel.shape[0])\n",
    "    row_buffer, col_buffer, val_buffer = populate_dh_buffers(d_origins, stacked_kernel, low_res_dim, high_res_dim, kernel.shape[0])\n",
    "    \n",
    "    return coo_matrix((val_buffer, (row_buffer, col_buffer)), shape=(low_res_dim**2, high_res_dim**2), dtype=np.float32)\n",
    "\n",
    "# @njit(parallel = True)\n",
    "def populate_dh_buffers(d_origins, kernel, low_res_dim, high_res_dim, original_kernel_samples):\n",
    "    \n",
    "    kernel_samples = kernel.shape[0]\n",
    "    kernel_offset = ((original_kernel_samples - 1) // 2) * (high_res_dim + 1)\n",
    "    kernel = kernel.flatten()\n",
    "    \n",
    "    buffer_strides = np.zeros(low_res_dim**2, dtype=np.uintc)\n",
    "    left_clip = np.zeros(low_res_dim**2, dtype=np.uintc)\n",
    "    right_clip = np.zeros(low_res_dim**2, dtype=np.uintc)\n",
    "    \n",
    "    # First pass to determine how big to make row/col/val buffers and the stride used for each thread to populate each respective row of DH\n",
    "    for i in prange(low_res_dim**2):\n",
    "        repeated_range = np.repeat(np.arange(kernel_samples, dtype=np.intc), kernel_samples)\n",
    "        cols = repeated_range.reshape(-1, kernel_samples).T.flatten() + (repeated_range * high_res_dim) + d_origins[i] - kernel_offset\n",
    "        left_clip[i] = cols[cols < 0].shape[0]\n",
    "        right_clip[i] = cols[cols >= high_res_dim**2].shape[0]\n",
    "    \n",
    "    samples_per_clipped_dh_row = kernel_samples**2 - (left_clip + right_clip)\n",
    "    total_samples = samples_per_clipped_dh_row.sum()\n",
    "    \n",
    "    # Below for Numba annotated func, cumsum doesnt support type...\n",
    "    # buffer_strides = np.append([0], np.cumsum(samples_per_clipped_dh_row))\n",
    "    # Below for regular func, cumsum requires dtype...\n",
    "    buffer_strides = np.append([0], np.cumsum(samples_per_clipped_dh_row, dtype=np.uintc)) # prepend 0 to allow for ranges\n",
    "    \n",
    "    row_buffer = np.zeros(total_samples, dtype=np.uintc)\n",
    "    col_buffer = np.zeros(total_samples, dtype=np.uintc)\n",
    "    val_buffer = np.zeros(total_samples, dtype=np.float32)\n",
    "    \n",
    "    # Second pass to populate the row/col/val buffers using predetermined strides and clipping parameters\n",
    "    for i in prange(low_res_dim**2):\n",
    "        repeated_range = np.repeat(np.arange(kernel_samples, dtype=np.intc), kernel_samples)\n",
    "        cols = repeated_range.reshape(-1, kernel_samples).T.flatten() + (repeated_range * high_res_dim) + d_origins[i] - kernel_offset\n",
    "        row_buffer[buffer_strides[i] : buffer_strides[i+1]] = i\n",
    "        col_buffer[buffer_strides[i] : buffer_strides[i+1]] = cols[left_clip[i] : kernel_samples**2 - right_clip[i]]\n",
    "        val_buffer[buffer_strides[i] : buffer_strides[i+1]] = kernel[left_clip[i] : kernel_samples**2 - right_clip[i]]\n",
    "        \n",
    "    return row_buffer, col_buffer, val_buffer\n",
    "\n",
    "### ===================================================================================================================\n",
    "### \n",
    "### ===================================================================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ===================================================================================================================\n",
    "### Batched approach\n",
    "### ===================================================================================================================\n",
    "\n",
    "def generate_dh_matrix_batched(kernel, high_res_dim, downsample, dh_matrix_batch_size):\n",
    "    \n",
    "    low_res_dim = high_res_dim // downsample\n",
    "    \n",
    "    # %lprun -f calculate_d_origins d_origins = calculate_d_origins(high_res_dim, downsample)\n",
    "    d_origins = calculate_d_origins(high_res_dim, downsample)\n",
    "    \n",
    "    # %lprun -f produce_stacked_kernel stacked_kernel = produce_stacked_kernel(kernel, downsample)\n",
    "    stacked_kernel = produce_stacked_kernel(kernel, downsample)\n",
    "    # show_image(stacked_kernel, \"Stacked\")\n",
    "    \n",
    "    # Placeholder matrix to be populated over time\n",
    "    m = coo_matrix((low_res_dim**2, high_res_dim**2), dtype=np.float32)\n",
    "\n",
    "    # Fill in entries for sparse DH matrix\n",
    "    for b in range(low_res_dim**2 // dh_matrix_batch_size):\n",
    "        # %lprun -f populate_dh_buffers row_buffer, col_buffer, val_buffer = populate_dh_buffers(d_origins, stacked_kernel, high_res_dim // downsample, high_res_dim, kernel.shape[0])\n",
    "        row_buffer, col_buffer, val_buffer = populate_dh_buffers_batched(d_origins, stacked_kernel, low_res_dim, high_res_dim, kernel.shape[0], dh_matrix_batch_size, b * dh_matrix_batch_size)\n",
    "        m += coo_matrix((val_buffer, (row_buffer, col_buffer)), shape=(low_res_dim**2, high_res_dim**2), dtype=np.float32)\n",
    "        # show_image(m.todense(), f\"Matrix (Batch {b})\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "@njit(parallel = True)\n",
    "def populate_dh_buffers_batched(d_origins, kernel, low_res_dim, high_res_dim, original_kernel_samples, batch_size, batch_offset):\n",
    "    \n",
    "    kernel_samples = kernel.shape[0]\n",
    "    kernel_offset = ((original_kernel_samples - 1) // 2) * (high_res_dim + 1)\n",
    "    kernel = kernel.flatten()\n",
    "    \n",
    "    buffer_strides = np.zeros(batch_size, dtype=np.uintc)\n",
    "    left_clip = np.zeros(batch_size, dtype=np.uintc)\n",
    "    right_clip = np.zeros(batch_size, dtype=np.uintc)\n",
    "    \n",
    "    # First pass to determine how big to make row/col/val buffers and the stride used for each thread to populate each respective row of DH\n",
    "    for i in prange(batch_size):\n",
    "        repeated_range = np.repeat(np.arange(kernel_samples).astype(np.intc), kernel_samples)\n",
    "        cols = repeated_range.reshape(-1, kernel_samples).T.flatten() + (repeated_range * high_res_dim) + d_origins[i+batch_offset] - kernel_offset\n",
    "        left_clip[i] = cols[cols < 0].shape[0]\n",
    "        right_clip[i] = cols[cols >= high_res_dim**2].shape[0]\n",
    "    \n",
    "    samples_per_clipped_dh_row = kernel_samples**2 - (left_clip + right_clip)\n",
    "    total_samples = samples_per_clipped_dh_row.sum()\n",
    "    \n",
    "    # Below for Numba annotated func, cumsum doesnt support type...\n",
    "    buffer_strides = np.append([0], np.cumsum(samples_per_clipped_dh_row))\n",
    "    # Below for regular func, cumsum requires dtype...\n",
    "    # buffer_strides = np.append([0], np.cumsum(samples_per_clipped_dh_row, dtype=np.uintc)) # prepend 0 to allow for ranges\n",
    "    \n",
    "    row_buffer = np.zeros(total_samples, dtype=np.uintc)\n",
    "    col_buffer = np.zeros(total_samples, dtype=np.uintc)\n",
    "    val_buffer = np.zeros(total_samples, dtype=np.float32)\n",
    "    \n",
    "    # Second pass to populate the row/col/val buffers using predetermined strides and clipping parameters\n",
    "    for i in prange(batch_size):\n",
    "        repeated_range = np.repeat(np.arange(kernel_samples).astype(np.intc), kernel_samples)\n",
    "        cols = repeated_range.reshape(-1, kernel_samples).T.flatten() + (repeated_range * high_res_dim) + d_origins[i+batch_offset] - kernel_offset\n",
    "        row_buffer[buffer_strides[i] : buffer_strides[i+1]] = i+batch_offset\n",
    "        col_buffer[buffer_strides[i] : buffer_strides[i+1]] = cols[left_clip[i] : kernel_samples**2 - right_clip[i]]\n",
    "        val_buffer[buffer_strides[i] : buffer_strides[i+1]] = kernel[left_clip[i] : kernel_samples**2 - right_clip[i]]\n",
    "        \n",
    "    return row_buffer, col_buffer, val_buffer\n",
    "\n",
    "### ===================================================================================================================\n",
    "### \n",
    "### ===================================================================================================================\n",
    "\n",
    "def produce_stacked_kernel(kernel, downsample):\n",
    "    \n",
    "    kernel_dim = kernel.shape[0]\n",
    "    stacked = np.zeros((kernel_dim + downsample - 1, kernel_dim + downsample - 1), dtype=np.float32)\n",
    "    for r in range(downsample):\n",
    "        for c in range(downsample):\n",
    "            stacked[r:r+kernel_dim, c:c+kernel_dim] += kernel\n",
    "    \n",
    "    return stacked\n",
    "\n",
    "# Calculates the first column index per row of D if we were to use D as a genuine downsampling matrix\n",
    "def calculate_d_origins(high_res_dim, downsample):\n",
    "    low_res_dim = high_res_dim // downsample\n",
    "    return np.tile(np.arange(0, high_res_dim, downsample, dtype=np.uintc), low_res_dim) + np.repeat(np.arange(low_res_dim, dtype=np.uintc) * high_res_dim * downsample, low_res_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7393b53-fb95-4227-8ac0-5083a94143e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dh_matrix_analysis import *\n",
    "# Params\n",
    "high_res_dim = 800\n",
    "low_res_dim = 400\n",
    "downsample = high_res_dim // low_res_dim\n",
    "\n",
    "# Blur kernel\n",
    "kernel_samples = 99\n",
    "kernel = gaussian_2d(kernel_samples)\n",
    "# show_image(kernel, \"Gaussian\")\n",
    "\n",
    "dh_matrix_batch_size = (low_res_dim**2) // 16 # needs to be a factor of low_res_dim**2 to ensure full coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce6dfca-44b4-46b8-97c9-5f38129e9d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 65.0961 s\n",
       "File: /supy_res/notebooks/dh_matrix_analysis.py\n",
       "Function: generate_dh_matrix_batched at line 77\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    77                                           def generate_dh_matrix_batched(kernel, high_res_dim, downsample, dh_matrix_batch_size):\n",
       "    78                                               \n",
       "    79         1          2.0      2.0      0.0      low_res_dim = high_res_dim // downsample\n",
       "    80                                               \n",
       "    81                                               # %lprun -f calculate_d_origins d_origins = calculate_d_origins(high_res_dim, downsample)\n",
       "    82         1       1781.0   1781.0      0.0      d_origins = calculate_d_origins(high_res_dim, downsample)\n",
       "    83                                               \n",
       "    84                                               # %lprun -f produce_stacked_kernel stacked_kernel = produce_stacked_kernel(kernel, downsample)\n",
       "    85         1        339.0    339.0      0.0      stacked_kernel = produce_stacked_kernel(kernel, downsample)\n",
       "    86                                               # show_image(stacked_kernel, \"Stacked\")\n",
       "    87                                               \n",
       "    88                                               # Placeholder matrix to be populated over time\n",
       "    89         1        228.0    228.0      0.0      m = coo_matrix((low_res_dim**2, high_res_dim**2), dtype=np.float32)\n",
       "    90                                           \n",
       "    91                                               # Fill in entries for sparse DH matrix\n",
       "    92        17         92.0      5.4      0.0      for b in range(low_res_dim**2 // dh_matrix_batch_size):\n",
       "    93                                                   # %lprun -f populate_dh_buffers row_buffer, col_buffer, val_buffer = populate_dh_buffers(d_origins, stacked_kernel, high_res_dim // downsample, high_res_dim, kernel.shape[0])\n",
       "    94        16   17370908.0 1085681.8     26.7          row_buffer, col_buffer, val_buffer = populate_dh_buffers_batched(d_origins, stacked_kernel, low_res_dim, high_res_dim, kernel.shape[0], dh_matrix_batch_size, b * dh_matrix_batch_size)\n",
       "    95        16   47722737.0 2982671.1     73.3          m += coo_matrix((val_buffer, (row_buffer, col_buffer)), shape=(low_res_dim**2, high_res_dim**2), dtype=np.float32)\n",
       "    96                                                   # show_image(m.todense(), f\"Matrix (Batch {b})\")\n",
       "    97                                               \n",
       "    98         1         11.0     11.0      0.0      return m.tocsr()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %lprun -f generate_dh_matrix m = generate_dh_matrix(kernel, high_res_dim, downsample)\n",
    "# %mprun -f generate_dh_matrix m = generate_dh_matrix(kernel, high_res_dim, downsample)\n",
    "\n",
    "# m = generate_dh_matrix(kernel, high_res_dim, downsample)\n",
    "\n",
    "# Around 1.5 mins for coo (no numba), \n",
    "# Around 1.3 mins for csr (no numba)\n",
    "# Around 5 mins for bsr (no numba)\n",
    "%lprun -f generate_dh_matrix_batched m = generate_dh_matrix_batched(kernel, high_res_dim, downsample, dh_matrix_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9987bd-9dd5-426c-8b5e-5479a4202a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400.640004\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(matrix_memory(m))\n",
    "print(type(m))\n",
    "# 7378.160004 for bsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79b9f48-b0cc-47d1-9491-5870c29f62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_sparse_matrix(m, \"Matrix\")\n",
    "# show_image(m.todense(), \"Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e7a56d-429b-4a55-bee6-1efe86e7d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Original method of producing decimation matrix D\n",
    "# d = generate_d_matrix(high_res_dim, downsample)\n",
    "# # # show_image(d.todense(), \"D Matrix\")\n",
    "\n",
    "# h = generate_h_matrix(high_res_dim, kernel)\n",
    "# # # show_image(h.todense(), \"H Matrix\")\n",
    "\n",
    "# dh = d @ h\n",
    "# # show_sparse_matrix(dh, \"DH Matrix\")\n",
    "# # show_image(dh.todense(), \"DH Mat\")\n",
    "\n",
    "# # show_image((dh.todense() - m.todense()), \"Diff\")\n",
    "# print(dh.power(2.0).sum())\n",
    "# print(m.power(2.0).sum())\n",
    "\n",
    "# # print((dh.power(2.0)).sum() - (m.power(2.0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85477d-3020-4896-9a9a-b35fa544a75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df997ea-90b2-4295-af72-dbaddb7c64e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

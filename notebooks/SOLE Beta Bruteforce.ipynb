{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88010b17-3fca-46db-90c5-82c558994c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from skimage import data, io, color\n",
    "from skimage.transform import resize\n",
    "from pandas import DataFrame\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "def show_image(image, title):\n",
    "    plt.imshow(image, cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def normalise(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def rrmse(observed, ideal):\n",
    "    return np.sqrt((1 / observed.shape[0]**2) * np.sum((observed-ideal)**2) / np.sum(ideal**2)) * 100.0\n",
    "\n",
    "def decimation_matrix(l, m):\n",
    "    d_matrix = np.zeros((m**2, l**2), dtype=np.float32)\n",
    "\n",
    "    tile = np.repeat((1, 0, 1), (2, l - 2, 2)) # assuming taking 2 neighbours per dimension\n",
    "    t_len = tile.shape[0]\n",
    "    d = l // m\n",
    "    r_offset = m**2 // 2\n",
    "    c_offset = l**2 // 2\n",
    "\n",
    "    for p in np.arange(l//4): # divide by 4 as 4 neighbours total\n",
    "        p_offset = p * l\n",
    "        for q in np.arange(m):\n",
    "            d_matrix[q+ p_offset//2, q*d + p_offset*2 : q*d+t_len + p_offset*2] = tile # top-left quadrant\n",
    "            d_matrix[q+r_offset + p_offset//2, q*d+c_offset + p_offset*2: q*d+t_len+c_offset + p_offset*2] = tile # bottom-right quadrant\n",
    "    return d_matrix\n",
    "\n",
    "# produces convolution matrix of size l**2 by l**2, where each row is populated by the convolution kernel values at the appropriate neighbours\n",
    "# note: assumes kernel is a two-dimensonal numpy array of some size n by n\n",
    "def convolution_matrix(l, kernel):\n",
    "    \n",
    "    conv = np.zeros((l**2, l**2), dtype=np.float32)\n",
    "    full_supp = kernel.shape[0] # assumed square\n",
    "    half_supp = (full_supp - 1) // 2\n",
    "\n",
    "    for conv_row in np.arange(l**2):\n",
    "\n",
    "        row, col = (conv_row // l, conv_row % l)\n",
    "\n",
    "        for k_row in np.arange(-(half_supp), half_supp + 1):\n",
    "            # map \"kernel row\" to rows in conv\n",
    "            mapped_row = row + k_row\n",
    "            # ignore any out of bounds rows\n",
    "            if mapped_row >= 0 and mapped_row < l:\n",
    "                linear_col = col - half_supp\n",
    "                # truncate negative columns\n",
    "                mapped_col_start = max(linear_col, 0)\n",
    "                # truncate columns which exceed the l dimension\n",
    "                mapped_col_end = min(linear_col + full_supp, l)\n",
    "                # left trimming for kernels when overlapping out of bounds region in conv (col < 0)\n",
    "                left = np.absolute(col - half_supp) if linear_col < 0 else 0\n",
    "                # right trimming for kernels when overlapping out of bounds region in conv (col >= l)\n",
    "                right = linear_col + full_supp - l if linear_col + full_supp >= l else 0 \n",
    "                # copy over kernel row for current k_row, possibly including trimming for out of bounds coordinates\n",
    "                conv[conv_row][mapped_row * l + mapped_col_start : mapped_row * l + mapped_col_end] = kernel[k_row + half_supp][left: left + full_supp - right]\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43bcb1-b9ed-4360-86fa-3da72cab75e7",
   "metadata": {},
   "source": [
    "#### Area under trimmed PSF as a percentage of the full PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28733b2-1cd1-4a81-bdf3-b18c1483acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 100\n",
    "# # all time steps direct psf\n",
    "# filename = \"../data/direct_psf_ts_0_29.bin\"\n",
    "# x_psf = np.fromfile(filename, dtype=np.float32)\n",
    "# x_psf = x_psf.reshape(l, l)\n",
    "# # x_psf /= np.max(x_psf)\n",
    "\n",
    "# x_psf_sum = np.sum(x_psf)\n",
    "# # print(f\"Full PSF sum under curve: {x_psf_sum}\")\n",
    "\n",
    "# psf_supports = []\n",
    "# area_under_curve = []\n",
    "\n",
    "# for s in np.arange(2, 51, 1): # 51\n",
    "#     psf_min = l//2 - (s - 1)\n",
    "#     psf_max = l//2 + s\n",
    "#     support = psf_max - psf_min\n",
    "#     trimmed_psf = x_psf[psf_min:psf_max, psf_min:psf_max]\n",
    "#     # trimmed_psf = trimmed_psf/np.sum(trimmed_psf)\n",
    "#     # print(np.sum(trimmed_psf))\n",
    "#     psf_area_percent = np.sum(trimmed_psf)/x_psf_sum * 100\n",
    "#     print(f\"PSF size: {support}x{support} => area under curve: {psf_area_percent}%\")\n",
    "#     psf_supports.append(support)\n",
    "#     area_under_curve.append(psf_area_percent)\n",
    "#     # print(trimmed_psf.shape)\n",
    "    \n",
    "# plt.plot(psf_supports, area_under_curve)\n",
    "# plt.title(\"Trimmed PSF Support versus Area Under Curve\")\n",
    "# plt.xlabel(\"PSF Support\")\n",
    "# plt.ylabel(\"Area (as percentage of full PSF)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b98346-6318-477d-8555-44909edbde9c",
   "metadata": {},
   "source": [
    "#### Brute force estimation of beta versus PSF support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d6ac0-ee73-4242-933b-01edb869a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_supports = np.arange(2, 51, 1) # 3 .. 99, taking all odd values in between\n",
    "# np.set_printoptions(suppress=True)\n",
    "# betas = np.geomspace(1, 50, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610532eb-0c5f-4946-81c5-70e8c237c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = DataFrame()\n",
    "\n",
    "psf_supports = np.arange(2, 19, 1) # 3 .. 35, taking all odd values in between\n",
    "betas = np.geomspace(0.1, 500.0, num=40)\n",
    "\n",
    "dataframe[\"Beta\"] = betas\n",
    "\n",
    "timesteps = 30 # total timesteps\n",
    "timesteps_per_y = 5\n",
    "l = 100\n",
    "m = 50\n",
    "n = timesteps // timesteps_per_y\n",
    "w = np.ones(n) # y image weightings, eventually driven by visibility weights\n",
    "\n",
    "# all time steps direct image\n",
    "# filename = \"../data/direct_image_ts_0_29.bin\"\n",
    "# x_true = np.fromfile(filename, dtype=np.float32)\n",
    "# x_true = x_true.reshape(l, l)\n",
    "# x_true = normalise(x_true)\n",
    "\n",
    "filename = \"../data/direct_image_ts_0_29_800x800.bin\"\n",
    "x_true = np.fromfile(filename, dtype=np.float32)\n",
    "x_true = resize(x_true.reshape(800, 800), (l, l), anti_aliasing=False, order=1)\n",
    "\n",
    "# all time steps direct psf\n",
    "# filename = \"../data/direct_psf_ts_0_29.bin\"\n",
    "# x_psf = np.fromfile(filename, dtype=np.float32)\n",
    "# x_psf = x_psf.reshape(l, l)\n",
    "# x_psf /= np.max(x_psf)\n",
    "\n",
    "filename = \"../data/direct_psf_ts_0_29_800x800.bin\"\n",
    "x_psf = np.fromfile(filename, dtype=np.float32)\n",
    "x_psf = resize(x_psf.reshape(800, 800), (l, l), anti_aliasing=False, order=1)\n",
    "\n",
    "# Storing all low-res images as layered stack\n",
    "y = np.zeros((n, m, m))\n",
    "\n",
    "# batched time steps direct images\n",
    "for i in np.arange(n):\n",
    "    filename = f\"../data/direct_image_ts_{i * timesteps_per_y}_{i * timesteps_per_y + timesteps_per_y - 1}.bin\"\n",
    "    y[i] = np.fromfile(filename, dtype=np.float32).reshape(m, m)\n",
    "    y[i] = normalise(y[i])\n",
    "\n",
    "# Decimation matrix\n",
    "d = decimation_matrix(l, m) # takes the sum of 4 l neighbours to form 1 m pixel\n",
    "\n",
    "# Sharpening matrix (laplacian)\n",
    "laplacian = np.array([[0, -1,  0], [-1,  4, -1], [0, -1,  0]], dtype=np.float32)\n",
    "s = convolution_matrix(l, laplacian)\n",
    "\n",
    "for psf_support in psf_supports:\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for beta in betas:\n",
    "\n",
    "        β = beta # sharpening factor\n",
    "\n",
    "        trim_half_len = psf_support\n",
    "        psf_min = l//2 - (trim_half_len - 1)\n",
    "        psf_max = l//2 + trim_half_len\n",
    "        support = psf_max - psf_min\n",
    "        x_psf_trim = x_psf[psf_min:psf_max, psf_min:psf_max]\n",
    "        x_psf_trim = x_psf_trim/np.sum(x_psf_trim)\n",
    "\n",
    "        print(f\"Processing support {support} with beta {β}\")\n",
    "\n",
    "        # Blur matrix (psf)\n",
    "        h = convolution_matrix(l, x_psf_trim)\n",
    "\n",
    "        b = np.zeros(l**2, dtype=np.float32)\n",
    "\n",
    "        for i in np.arange(n):\n",
    "            b += np.matmul(w[i] * h.T, np.matmul(d.T, y[i].flatten()))                  \n",
    "        # show_image(normalise(b.reshape(l, l)), \"B\")\n",
    "\n",
    "        lhs = β * np.matmul(s.T, s)\n",
    "        rhs = (h.T @ d.T @ d @ h) * np.sum(w)\n",
    "        a = lhs + rhs\n",
    "        # show_image(a.reshape(l**2, l**2), \"A\")\n",
    "\n",
    "        x = np.linalg.solve(a, b)\n",
    "        x = x.reshape(100, 100)\n",
    "        error = rrmse(normalise(x), normalise(x_true))\n",
    "        # print(f\"RRMSE: Solved X and True X -> {error}\")\n",
    "        errors.append(error)\n",
    "\n",
    "        if beta == betas[-1]: # if last iteration\n",
    "            print(\"Last iteration...\")\n",
    "            dataframe[f\"{support}x{support}\"] = errors\n",
    "\n",
    "        # show_image(normalise(x), \"Solved X\")\n",
    "        # show_image(normalise(x_true), \"True X\")\n",
    "    \n",
    "# Finally, write the results to a spreadsheet...\n",
    "dataframe.to_excel('../beta_bruteforce.xlsx', sheet_name='beta_vs_rrmse', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8296515-9466-4e72-9824-70b543b9b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(betas, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efb938-08d4-4dc6-97e0-0754fe38ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

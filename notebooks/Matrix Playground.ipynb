{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbc35d-0690-4aa4-b6eb-34f65f15cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for memory usage profiling\n",
    "%load_ext memory_profiler\n",
    "# Needed for runtime profiling\n",
    "%load_ext line_profiler\n",
    "# Needed for static or interactive matplotlib plots\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.sparse import bsr_matrix, diags, dia_matrix, csr_matrix\n",
    "\n",
    "from skimage import data, io, color\n",
    "from skimage.transform import resize\n",
    "\n",
    "from array import array\n",
    "\n",
    "def matrix_memory(m):\n",
    "    return (m.data.nbytes + m.indptr.nbytes + m.indices.nbytes) / 10**6 # MB\n",
    "\n",
    "def matrix_density(m):\n",
    "    return m.getnnz() / np.prod(m.shape)\n",
    "\n",
    "def show_image(image, title):\n",
    "    plt.imshow(image, cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def show_sparse_matrix(image, title):\n",
    "    plt.spy(image)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def normalise(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def linear_to_row_col(index, row_width):\n",
    "    return (index // row_width, index % row_width)\n",
    "\n",
    "# 2D gaussian blur\n",
    "def gkern(l=5, sig=1.):\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd35db-31a3-492e-9a76-d5ef7948a7ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compressed sparse decimation matrix with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b4b95-f955-486e-b1dc-d7d3edb2638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decimation_matrix(original_dim, downsample_factor, padding):\n",
    "    \n",
    "#     if original_dim % downsample_factor != 0:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} is not a valid factor of your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == original_dim:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} cannot be the same as your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == 1: # effectively, no downsampling\n",
    "#         return np.identity(original_dim**2)\n",
    "#     # Otherwise assumed you want to downsample by a valid factor of original_dim...\n",
    "    \n",
    "#     sampling_regions_per_dim = original_dim // downsample_factor\n",
    "#     samples_per_region_dim = downsample_factor\n",
    "#     # print(f\"Sampling regions per dimension: {sampling_regions_per_dim}\")\n",
    "#     # print(f\"Samples per dimension: {samples_per_region_dim}\")\n",
    "#     non_zero_entries = sampling_regions_per_dim**2 * samples_per_region_dim**2\n",
    "#     # print(f\"Non-zero entries: {non_zero_entries}\")\n",
    "    \n",
    "#     rows = np.zeros(non_zero_entries, dtype=np.uintc)   # stores row indices for non-zero compressed sparse matrix entries\n",
    "#     cols = np.zeros(non_zero_entries, dtype=np.uintc)   # stores col indices for non-zero compressed sparse matrix entries\n",
    "#     vals = np.ones(non_zero_entries, dtype=np.float32)  # stores element value at [row, col] for non-zero entries\n",
    "    \n",
    "#     # Generates linear x,y index strides for downsampling\n",
    "#     sample_stride_1D = np.arange(0, original_dim, downsample_factor)\n",
    "#     # print(sample_stride_1D)\n",
    "#     mesh = np.array(np.meshgrid(sample_stride_1D, sample_stride_1D))\n",
    "#     sample_strides_2D = mesh.T.reshape(-1, 2)\n",
    "  \n",
    "#     neighbour_strides_1D = np.arange(samples_per_region_dim)\n",
    "#     neighbour_mesh = np.array(np.meshgrid(neighbour_strides_1D, neighbour_strides_1D))\n",
    "\n",
    "#     for index in np.arange(sample_strides_2D.shape[0]):\n",
    "#         neighbour_coords = neighbour_mesh.T.reshape(-1, 2) + sample_strides_2D[index] # generates (row, col) index pair for the nxn neighbours of each sampling point in sample_strides_2D\n",
    "#         neighbour_coords[:, 0] *= original_dim # scale y coord by high-resolution image dim to enable row striding (due to column-vector matrix flattening)\n",
    "#         neighbour_coords = np.sum(neighbour_coords, axis=1) # combine x and y coord into single array index\n",
    "#         rows[index * neighbour_coords.shape[0] : (index + 1) * neighbour_coords.shape[0]] = index\n",
    "#         cols[index * neighbour_coords.shape[0] : (index + 1) * neighbour_coords.shape[0]] = neighbour_coords\n",
    "        \n",
    "#     return csr_matrix((vals, (rows, cols)), shape=(sampling_regions_per_dim**2, sampling_regions_per_dim**4))\n",
    "\n",
    "# d_factor = 5\n",
    "# l = 25\n",
    "# m = l//d_factor\n",
    "# padding = 1\n",
    "\n",
    "# x_true = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "# x = np.pad(x, padding)\n",
    "# show_image(normalise(x), \"X\")\n",
    "# d = decimation_matrix(l, d_factor, padding)\n",
    "# show_sparse_matrix(d, \"D Matrix\")\n",
    "# # x_deci = x.reshape(1, x.shape[0]**2)\n",
    "# # x_deci = d @ x_deci.T\n",
    "# # x_deci = x_deci.reshape(m, m)\n",
    "# # show_image(normalise(x_deci), \"X Deci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc9e71-db48-4cbf-a2e5-86d3075d36cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compressed sparse \"convolution\" matrices with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd97b5-bede-47da-b13a-5881464e8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def janky_conv_matrix(l, kernel):\n",
    "#     k_supp = kernel.shape[0]\n",
    "#     k_half_supp = (k_supp-1)//2\n",
    "#     k_samples = k_supp**2\n",
    "#     col_offsets = np.repeat(np.arange(k_supp) - k_half_supp, k_supp) * (l - k_supp)\n",
    "#     diagonal_offsets = (np.arange(k_samples) - (k_samples-1)//2) + col_offsets\n",
    "#     return dia_matrix.tocsr(diags(kernel.flatten(), diagonal_offsets, shape=(l**2, l**2)))\n",
    "\n",
    "# l = 4\n",
    "# # kernel = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=np.float32)\n",
    "# kernel = gkern(3).astype(np.float32)\n",
    "# print(kernel)\n",
    "# k_supp = (kernel.shape[0] - 1) // 2\n",
    "\n",
    "# %time m = janky_conv_matrix(l, kernel)\n",
    "# # print(f\"M matrix memory usage: {matrix_memory(m)}MB\")\n",
    "# # print(f\"M matrix density: {matrix_density(m)}%\")\n",
    "# show_sparse_matrix(m, \"M\")\n",
    "\n",
    "# # x_true = color.rgb2gray(data.astronaut())\n",
    "# x_true = data.camera()\n",
    "# x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "\n",
    "# scikit_convolved = normalise(convolve2d(x, kernel, mode=\"same\"))\n",
    "# show_image(x, \"X\")\n",
    "\n",
    "# print(x.shape)\n",
    "# print(m.shape)\n",
    "\n",
    "# x = x.reshape(1, x.shape[0]**2)\n",
    "# x = m @ x.T\n",
    "# x = x.reshape(l, l)\n",
    "# print(x.shape)\n",
    "        \n",
    "# # optional trimming, needed because edges are janky with this approach\n",
    "# # x = x[50 : l - 50, 50 : l - 50]\n",
    "# # scikit_convolved = scikit_convolved[50 : l - 50, 50 : l - 50]\n",
    "    \n",
    "# show_image(normalise(x), \"Sharpened X\")\n",
    "# show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "# show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a0588-5b54-4614-8f31-ea1c7c8d343b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compressed sparse \"convolution\" matrix hack job\n",
    "Note: does not handle image edges correctly - no padding, no trimming, nothing. So your resulting image that this matrix applies to will need to be trimmed around the edge by about half the support of your convolution kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41a920-79a0-41ab-83c8-ced1a6b816d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89947e5-56dd-41d3-8990-d69ddbf23dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "l = 400\n",
    "\n",
    "# kernel = np.array([[1, -1, 1], [-1, 4, -1], [1, -1, 1]], dtype=np.float32)\n",
    "kernel = gkern(31).astype(np.float32)\n",
    "k_supp = kernel.shape[0]\n",
    "k_half_supp = (k_supp-1)//2\n",
    "\n",
    "def janky_conv_matrix(l, kernel):\n",
    "    k_supp = kernel.shape[0]\n",
    "    k_half_supp = (k_supp-1)//2\n",
    "    k_samples = k_supp**2\n",
    "    col_offsets = np.repeat(np.arange(k_supp) - k_half_supp, k_supp) * (l - k_supp)\n",
    "    diagonal_offsets = (np.arange(k_samples) - (k_samples-1)//2) + col_offsets\n",
    "    return diags(kernel.flatten(), diagonal_offsets, format=\"csr\", shape=(l**2, l**2))\n",
    "\n",
    "def apply_mask(r, l, k_half_supp, m, mask):\n",
    "    col_chunk_min = max(0, r-k_half_supp-1)\n",
    "    col_chunk_max = min(l-1, r+k_half_supp+1)\n",
    "    for c in range(col_chunk_min, col_chunk_max+1): # need to process only partial column chunks, probably needs parallelisation...\n",
    "        m[r*l:r*l+l, c*l:c*l+l] = m[r*l:r*l+l, c*l:c*l+l].multiply(mask)\n",
    "\n",
    "m = janky_conv_matrix(l, kernel)\n",
    "# print((m.data.nbytes + m.indptr.nbytes + m.indices.nbytes) / 10**6)\n",
    "# show_sparse_matrix(m, \"Sparse Diags\")\n",
    "# show_image(m.todense(), \"M\")\n",
    "\n",
    "# Trying to generate splice matrix to remove bad convolution entries\n",
    "mask_vals = np.repeat(1.0, k_supp)\n",
    "# print(mask_vals)\n",
    "mask_offsets = np.linspace(-k_half_supp, k_half_supp, k_supp, dtype=np.intc)\n",
    "# print(mask_offsets)\n",
    "mask = diags(mask_vals, mask_offsets, shape=(l, l), format=\"csr\", dtype=np.float32)\n",
    "# show_image(mask.todense(), \"Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254956a7-d705-464e-b326-a271b8f3d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Apply mask over non-zero regions of sparse 'diag' matrix\n",
    "# for r in range(l): # need to process all row chunks    \n",
    "#     apply_mask(r, l, k_half_supp, m, mask)\n",
    "    \n",
    "# https://superfastpython.com/multiprocessing-pool-for-loop/#Parallel_For-Loop_with_map_and_No_Return_Values\n",
    "\n",
    "try:\n",
    "    Parallel(n_jobs=-1, prefer='threads')(delayed(apply_mask)(row, l, k_half_supp, m, mask) for row in range(l))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc9bd6-55c7-43c5-8033-7922abeb11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((m.data.nbytes + m.indptr.nbytes + m.indices.nbytes) / 10**6)\n",
    "# show_image(m.todense(), \"M\")\n",
    "        \n",
    "x_true = color.rgb2gray(data.astronaut())\n",
    "x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "show_image(x, \"X\")\n",
    "\n",
    "scikit_convolved = normalise(convolve2d(x, kernel.reshape(k_supp, k_supp), mode=\"same\"))\n",
    "show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "\n",
    "x = x.reshape(1, x.shape[0]**2)\n",
    "x = m @ x.T\n",
    "x = x.reshape(l, l)\n",
    "        \n",
    "# optional trimming, needed because edges are janky with this approach\n",
    "# x = x[50 : l - 50, 50 : l - 50]\n",
    "# scikit_convolved = scikit_convolved[50 : l - 50, 50 : l - 50]\n",
    "    \n",
    "show_image(normalise(x), \"Sharpened X\")\n",
    "show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fb6a0-1932-428e-a19c-5ca060a89079",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Decimation matrix (row major) - assumes only taking 4 neighbours and that $L = M*2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe90ef-c36d-42a4-97d9-6cf48eb2ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 4\n",
    "# m = 2\n",
    "# d = l // m\n",
    "\n",
    "# d_matrix = np.zeros((m**2, l**2))\n",
    "\n",
    "# tile = np.repeat((1, 0, 1), (2, l - 2, 2)) # assuming taking 2 neighbours per dimension\n",
    "# t_len = tile.shape[0]\n",
    "\n",
    "# for p in np.arange(l//4):\n",
    "#     p_offset = p * l # 8\n",
    "#     for q in np.arange(m):\n",
    "#         d_matrix[q+ p_offset//2, q*d + p_offset*2 : q*d+t_len + p_offset*2] = tile # top-left quadrant\n",
    "#         r_offset = m**2 // 2\n",
    "#         c_offset = l**2 // 2\n",
    "#         d_matrix[q+r_offset + p_offset//2, q*d+c_offset + p_offset*2: q*d+t_len+c_offset + p_offset*2] = tile # bottom-right quadrant\n",
    "        \n",
    "# print(d_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa309fc-df94-43db-ba2b-4880e9fd692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(1, 65) # 1..64\n",
    "# print(x.reshape(8, 8))\n",
    "\n",
    "# y = np.matmul(d_matrix * 1/4, x)\n",
    "# print(y.reshape(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19690611-6387-4989-bfd9-054710062f70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Decimation matrix - downsample matrix $l^2$ by integer factor $n$ (assumes $n$ is suitable factor of $l$ shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71a3c6-5d6a-4704-bcd3-f05cdeb93dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decimation_matrix(original_dim, downsample_factor):\n",
    "    \n",
    "#     if original_dim % downsample_factor != 0:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} is not a valid factor of your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == original_dim:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} cannot be the same as your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == 1: # effectively, no downsampling\n",
    "#         return np.identity(original_dim**2)\n",
    "#     # Otherwise assumed you want to downsample by a valid factor of original_dim...\n",
    "    \n",
    "#     sampling_regions_per_dim = original_dim // downsample_factor\n",
    "#     samples_per_region_dim = downsample_factor\n",
    "#     # print(f\"Sampling regions per dimension: {sampling_regions_per_dim}\")\n",
    "#     deci = np.zeros((sampling_regions_per_dim**2, original_dim**2))\n",
    "#     # print(deci.shape)\n",
    "    \n",
    "#     # Generates linear x,y index strides for downsampling\n",
    "#     sample_stride_1D = np.arange(0, original_dim, downsample_factor)\n",
    "#     # print(sample_stride_1D)\n",
    "#     mesh = np.array(np.meshgrid(sample_stride_1D, sample_stride_1D))\n",
    "#     sample_strides_2D = mesh.T.reshape(-1, 2)\n",
    "#     # print(sample_strides_2D)\n",
    "  \n",
    "#     neighbour_strides_1D = np.arange(samples_per_region_dim)\n",
    "#     neighbour_mesh = np.array(np.meshgrid(neighbour_strides_1D, neighbour_strides_1D))\n",
    "\n",
    "#     for index in np.arange(sample_strides_2D.shape[0]):\n",
    "#         neighbour_coords = neighbour_mesh.T.reshape(-1, 2) + sample_strides_2D[index] # generates (row, col) index pair for the nxn neighbours of each sampling point in sample_strides_2D\n",
    "#         neighbour_coords[:, 0] *= original_dim # scale y coord by high-resolution image dim to enable row striding (due to column-vector matrix flattening)\n",
    "#         neighbour_coords = np.sum(neighbour_coords, axis=1) # combine x and y coord into single array index\n",
    "#         deci[index, neighbour_coords] = 1.0\n",
    "        \n",
    "#     return deci\n",
    "    \n",
    "# # Testing of new decimation matrix routine\n",
    "# l = np.arange(9**2)\n",
    "# print(l.reshape(9, 9))\n",
    "# d = decimation_matrix(9, 3)\n",
    "# show_plot(d)\n",
    "# m = d @ l\n",
    "# print(m.shape)\n",
    "# print(m.reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcb722-f9ee-4c31-ab2d-7d2ff07e3712",
   "metadata": {},
   "source": [
    "Decimation matrix using the [Block Sparse Row (BSR) matrix format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy-sparse-bsr-matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485d3ab-dc76-4efa-9c9c-cd104764d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decimation_matrix(original_dim, downsample_factor):\n",
    "    \n",
    "#     if original_dim % downsample_factor != 0:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} is not a valid factor of your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == original_dim:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} cannot be the same as your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == 1: # effectively, no downsampling\n",
    "#         return np.identity(original_dim**2)\n",
    "#     # Otherwise assumed you want to downsample by a valid factor of original_dim...\n",
    "    \n",
    "#     sampling_regions_per_dim = original_dim // downsample_factor\n",
    "#     samples_per_region_dim = downsample_factor\n",
    "#     # print(f\"Sampling regions per dimension: {sampling_regions_per_dim}\")\n",
    "#     # print(f\"Samples per dimension: {samples_per_region_dim}\")\n",
    "#     non_zero_entries = sampling_regions_per_dim**2 * samples_per_region_dim**2\n",
    "#     # print(f\"Non-zero entries: {non_zero_entries}\")\n",
    "    \n",
    "#     rows = np.zeros(non_zero_entries, dtype=np.uintc)   # stores row indices for non-zero compressed sparse matrix entries\n",
    "#     cols = np.zeros(non_zero_entries, dtype=np.uintc)   # stores col indices for non-zero compressed sparse matrix entries\n",
    "#     vals = np.ones(non_zero_entries, dtype=np.float32)  # stores element value at [row, col] for non-zero entries\n",
    "    \n",
    "#     # Generates linear x,y index strides for downsampling\n",
    "#     sample_stride_1D = np.arange(0, original_dim, downsample_factor)\n",
    "#     # print(sample_stride_1D)\n",
    "#     mesh = np.array(np.meshgrid(sample_stride_1D, sample_stride_1D))\n",
    "#     sample_strides_2D = mesh.T.reshape(-1, 2)\n",
    "  \n",
    "#     neighbour_strides_1D = np.arange(samples_per_region_dim)\n",
    "#     neighbour_mesh = np.array(np.meshgrid(neighbour_strides_1D, neighbour_strides_1D))\n",
    "\n",
    "#     for index in np.arange(sample_strides_2D.shape[0]):\n",
    "#         neighbour_coords = neighbour_mesh.T.reshape(-1, 2) + sample_strides_2D[index] # generates (row, col) index pair for the nxn neighbours of each sampling point in sample_strides_2D\n",
    "#         neighbour_coords[:, 0] *= original_dim # scale y coord by high-resolution image dim to enable row striding (due to column-vector matrix flattening)\n",
    "#         neighbour_coords = np.sum(neighbour_coords, axis=1) # combine x and y coord into single array index\n",
    "#         rows[index * neighbour_coords.shape[0] : (index + 1) * neighbour_coords.shape[0]] = index\n",
    "#         cols[index * neighbour_coords.shape[0] : (index + 1) * neighbour_coords.shape[0]] = neighbour_coords\n",
    "        \n",
    "#     return bsr_matrix((vals, (rows, cols)))\n",
    "    \n",
    "# # Testing of new decimation matrix routine\n",
    "# l_dim = 8\n",
    "# deci_factor = 4\n",
    "\n",
    "# l = np.arange(l_dim**2)\n",
    "# print(l.reshape(l_dim, l_dim))\n",
    "# d = decimation_matrix(l_dim, deci_factor)\n",
    "# print(type(d))\n",
    "# print((d.data.nbytes + d.indptr.nbytes + d.indices.nbytes) / 10**6)\n",
    "# # print(d)\n",
    "# # show_image(d, \"D\")\n",
    "# m = d @ l\n",
    "# print(m.shape)\n",
    "# print(m.reshape(l_dim//deci_factor, l_dim//deci_factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970d022-cf44-4a74-a1f5-5829da2507da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Sharpening matrix (padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8135b9-0a70-4508-a23f-7637ee572d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_true = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x_true, (100, 100), anti_aliasing=True)\n",
    "# show_plot(x)\n",
    "\n",
    "# laplace_deblur = np.array([[0, -1,  0], [-1,  4, -1], [0, -1,  0]], dtype=np.float32)\n",
    "# scikit_convolved = normalise(convolve2d(x, laplace_deblur, mode=\"same\"))\n",
    "# show_plot(scikit_convolved)\n",
    "\n",
    "# l = x.shape[0]\n",
    "# laplacian = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=np.float32)\n",
    "# laplacian_dim = laplacian.shape[0]\n",
    "# padding = laplacian_dim - 1 # s_matrix padding for out of bounds convolution\n",
    "# laplacian = laplacian.flatten()\n",
    "# strided_laplacian = np.insert(laplacian, laplacian_dim, np.repeat(0, l-1))\n",
    "# strided_laplacian = np.insert(strided_laplacian, laplacian_dim*2+l-1, np.repeat(0, l-1))\n",
    "# s_matrix = np.zeros(((l+padding)**2, (l+padding)**2), dtype=np.float32)\n",
    "\n",
    "# for sr in np.arange(l):\n",
    "#     for r in np.arange(l):\n",
    "#         row_offset = (sr*l)+(l+padding+padding//2)+(padding*sr)\n",
    "#         col_offset = sr*(l+padding)+r\n",
    "#         s_matrix[row_offset+r, col_offset:col_offset+strided_laplacian.shape[0]] = strided_laplacian\n",
    "\n",
    "# show_plot(s_matrix)\n",
    "        \n",
    "# x_padded = np.pad(x, 1)\n",
    "# x_padded = x_padded.reshape(1, x_padded.shape[0]**2)\n",
    "# x_padded = np.matmul(s_matrix, x_padded.T)\n",
    "# x_padded = x_padded.reshape(102, 102)[1:101, 1:101]\n",
    "        \n",
    "# show_plot(normalise(x_padded))\n",
    "# show_plot(scikit_convolved - normalise(x_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a4853-e2af-4d4c-8a04-da18eee98ff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Convolution matrix (no padding, sharpening example) using the [Block Sparse Row (BSR) matrix format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy-sparse-bsr-matrix)\n",
    "##### (Note: only works for small samples... it is too much of a memory hog...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08f2b0-91be-4b69-94d8-572d77d3ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_matrix(l, kernel):\n",
    "    conv = np.zeros((l**2, l**2), dtype=np.float32)\n",
    "    full_supp = kernel.shape[0] # assumed square\n",
    "    half_supp = (full_supp - 1) // 2\n",
    "\n",
    "    for conv_row in np.arange(l**2):\n",
    "\n",
    "        row, col = (conv_row // l, conv_row % l)\n",
    "\n",
    "        for k_row in np.arange(-(half_supp), half_supp + 1):\n",
    "            # map \"kernel row\" to rows in conv\n",
    "            mapped_row = row + k_row\n",
    "            # ignore any out of bounds rows\n",
    "            if mapped_row >= 0 and mapped_row < l:\n",
    "                linear_col = col - half_supp\n",
    "                # truncate negative columns\n",
    "                mapped_col_start = max(linear_col, 0)\n",
    "                # truncate columns which exceed the l dimension\n",
    "                mapped_col_end = min(linear_col + full_supp, l)\n",
    "                # left trimming for kernels when overlapping out of bounds region in conv (col < 0)\n",
    "                left = np.absolute(col - half_supp) if linear_col < 0 else 0\n",
    "                # right trimming for kernels when overlapping out of bounds region in conv (col >= l)\n",
    "                right = linear_col + full_supp - l if linear_col + full_supp >= l else 0 \n",
    "                # copy over kernel row for current k_row, possibly including trimming for out of bounds coordinates\n",
    "                conv[conv_row][mapped_row * l + mapped_col_start : mapped_row * l + mapped_col_end] = kernel[k_row + half_supp][left: left + full_supp - right]\n",
    "    return conv\n",
    "\n",
    "l = 10\n",
    "x_true = color.rgb2gray(data.astronaut())\n",
    "x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "# show_image(x, \"X\")\n",
    "\n",
    "# laplace = np.array([[1, -1,  1], [-1,  4, -1], [1, -1,  1]], dtype=np.float32)\n",
    "laplace = np.array([[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7], [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]], dtype=np.float32) * 1/273\n",
    "full_supp = laplace.shape[0] # assumed square\n",
    "half_supp = (full_supp - 1) // 2\n",
    "kernel_samples = full_supp**2\n",
    "\n",
    "non_zero_entries = full_supp**2 * l**2\n",
    "# print(f\"Total non-zero entries: {non_zero_entries}\")\n",
    "rows = np.zeros(non_zero_entries, dtype=np.uintc)\n",
    "cols = np.zeros(non_zero_entries, dtype=np.intc)\n",
    "vals = np.zeros(non_zero_entries, dtype=np.float32)\n",
    "\n",
    "# for each flattened \"convolution\" row in matrix\n",
    "for m_row in np.arange(l**2):\n",
    "    \n",
    "    # map flattened m_row to 2d row/col  \n",
    "    row, col = (m_row // l, m_row % l)\n",
    "    # print(f\"M_row {m_row} maps to row/col {row}, {col}\")\n",
    "    \n",
    "    # map kernel to neighbouring indices of row/col, from centre of kernel\n",
    "    neighbour_rows =  np.arange(-(half_supp), half_supp+1) + row\n",
    "    neighbour_cols = np.arange(-(half_supp), half_supp+1) + col\n",
    "    mesh = np.array(np.meshgrid(neighbour_rows, neighbour_cols))\n",
    "    neighbour_indices = mesh.T.reshape(-1, 2)\n",
    "    \n",
    "    # zero out in kernel, any neighbours which have negative index or greater than l\n",
    "    bad_rows = np.concatenate((np.where(neighbour_indices[:, 0] < 0)[0], np.where(neighbour_indices[:, 0] >= l)[0]))\n",
    "    bad_cols = np.concatenate((np.where(neighbour_indices[:, 1] < 0)[0], np.where(neighbour_indices[:, 1] >= l)[0]))\n",
    "    # get a set of distinct neighbours to be zeroed out (in case of duplicate entries where a bad row is also a bad column)\n",
    "    bad_neighbours = np.unique(np.concatenate((bad_rows, bad_cols)))\n",
    "    # print(bad_neighbours)\n",
    "    \n",
    "    kernel = laplace.flatten()\n",
    "    kernel[bad_neighbours] = 0.0\n",
    "    \n",
    "    start = m_row * full_supp**2\n",
    "    end = (m_row + 1) * full_supp**2\n",
    "    col_strides = np.repeat((np.arange(-half_supp, half_supp + 1)), (np.repeat(full_supp, full_supp))) * (l - full_supp)\n",
    "    # populating row indices and flattened kernel slices\n",
    "    rows[start:end] = m_row\n",
    "    cols[start:end] = (np.arange(m_row, m_row + full_supp**2) - full_supp**2 // 2 + col_strides)\n",
    "    vals[start:end] = kernel\n",
    "    \n",
    "# strip away any entries in rows/cols/vals where cols < 0, cols >= l**2, or where val is zero\n",
    "out_of_bounds_or_zero = np.concatenate((np.where(cols < 0), np.where(cols >= l**2), np.where(vals == 0.0)), axis=None)\n",
    "rows = np.delete(rows, out_of_bounds_or_zero)\n",
    "cols = np.delete(cols, out_of_bounds_or_zero)\n",
    "vals = np.delete(vals, out_of_bounds_or_zero)\n",
    "\n",
    "# original_method = convolution_matrix(l, laplace.reshape(full_supp, full_supp))\n",
    "# # print((original_method.size * original_method.itemsize) / 10**6)\n",
    "# show_image(original_method, \"Original Sharpening matrix\")\n",
    "\n",
    "conv_matrix = bsr_matrix((vals, (rows, cols)))\n",
    "# print((conv_matrix.data.nbytes + conv_matrix.indptr.nbytes + conv_matrix.indices.nbytes) / 10**6)\n",
    "show_image(conv_matrix.todense(), \"Sharpening matrix\")\n",
    "\n",
    "scikit_convolved = normalise(convolve2d(x, laplace.reshape(full_supp, full_supp), mode=\"same\"))\n",
    "# show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "\n",
    "x = x.reshape(1, x.shape[0]**2)\n",
    "x = conv_matrix.todense() @ x.T\n",
    "# # x = original_method @ x.T\n",
    "x = x.reshape(l, l)\n",
    "    \n",
    "show_image(conv_matrix.todense()[:10, :10], \"Sharpening matrix\")\n",
    "    \n",
    "# show_image(normalise(x), \"Sharpened X\")\n",
    "# show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a454ed-a276-4ab1-a0cf-9d73a5fead66",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Convolution matrix (no padding, sharpening example) using a dictionary (for efficiency?) and the [Block Sparse Row (BSR) matrix format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy-sparse-bsr-matrix)\n",
    "*The assumption is that I can maintain a top-level dictionary, where the key = the convolution kernel sample, and the value is a secondary dictionary, where the key-value pair is the row and column index of said kernel sample. From there, I should in theory be able to generate appropriately sized row/col/sample numpy arrays only containing valid entries in the convolution matrix, built using the CSR or BSR format...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d227716-e309-4ec5-8f6b-3a459b94c0de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%file conv_matrix_sparse.py\n",
    "# import numpy as np\n",
    "# from scipy.sparse import bsr_matrix\n",
    "\n",
    "# def convolution_matrix_sparse(l, kernel):\n",
    "    \n",
    "#     # Allocate a key-value pair for each distinct kernel sample (key) to an empty list (value) \n",
    "#     pixel_to_row_col_dict = {val : [] for val in np.unique(kernel)}\n",
    "#     full_supp = kernel.shape[0] # assumed square\n",
    "#     half_supp = (full_supp - 1) // 2\n",
    "    \n",
    "#     kernel = kernel.flatten()\n",
    "#     neighbour_strides = np.arange(-(half_supp), half_supp+1)\n",
    "    \n",
    "#     for m_row in np.arange(l**2):\n",
    "        \n",
    "#         # map flattened m_row to 2d row/col  \n",
    "#         row, col = (m_row // l, m_row % l)\n",
    "#         # print(f\"M_row {m_row} maps to row/col {row}, {col}\")\n",
    "        \n",
    "#         neighbour_rows = neighbour_strides + row\n",
    "#         neighbour_cols = neighbour_strides + col\n",
    "        \n",
    "#         # map kernel to neighbouring indices of row/col, from centre of kernel\n",
    "#         meshgrid = np.meshgrid(neighbour_rows, neighbour_cols, copy=False)\n",
    "#         mesh = np.array(meshgrid)\n",
    "#         neighbour_indices = mesh.T.reshape(-1, 2)\n",
    "        \n",
    "#         # zero out in kernel, any neighbours which have negative index or greater than l\n",
    "#         bad_rows = np.concatenate((np.where(neighbour_indices[:, 0] < 0)[0], np.where(neighbour_indices[:, 0] >= l)[0]))\n",
    "#         bad_cols = np.concatenate((np.where(neighbour_indices[:, 1] < 0)[0], np.where(neighbour_indices[:, 1] >= l)[0]))\n",
    "#         # get a set of distinct neighbours to be zeroed out (in case of duplicate entries where a bad row is also a bad column)\n",
    "#         bad_neighbours = np.unique(np.concatenate((bad_rows, bad_cols)))\n",
    "#         # print(f\"Bad neighbours: {bad_neighbours}\")\n",
    "\n",
    "#         modified_kernel = np.copy(kernel)\n",
    "#         # print(f\"Original kernel: {modified_kernel}\")\n",
    "#         modified_kernel = np.delete(modified_kernel, bad_neighbours)\n",
    "#         # print(f\"Modified kernel: {modified_kernel}\")\n",
    "#         col_strides = np.repeat(neighbour_strides, (np.repeat(full_supp, full_supp))) * (l - full_supp)\n",
    "#         # print(f\"Col Strides: {col_strides}\")\n",
    "#         cols = np.delete((np.arange(m_row, m_row + full_supp**2) - full_supp**2 // 2 + col_strides), bad_neighbours)\n",
    "        \n",
    "#         # print(f\"Column vals: {cols}\")\n",
    "#         for index, entry in enumerate(modified_kernel):\n",
    "#             pixel_to_row_col_dict[entry].append((m_row, cols[index]))\n",
    "        \n",
    "#     entries = sum(len(v) for v in pixel_to_row_col_dict.values())\n",
    "#     # print(entries)\n",
    "\n",
    "#     row_col_pairs = np.zeros((entries, 2), dtype=np.uintc)\n",
    "#     kernel_samples = np.zeros(entries, dtype=np.float32)\n",
    "#     stride = 0\n",
    "#     for k, v in pixel_to_row_col_dict.items():\n",
    "\n",
    "#         if not v: # ignore pixels with no entries\n",
    "#             continue\n",
    "\n",
    "#         multiplier = len(v)\n",
    "#         # print(multiplier)\n",
    "#         kernel_samples[stride : stride + multiplier] = k\n",
    "#         row_col_pairs[stride : stride + multiplier] = v\n",
    "#         stride += multiplier\n",
    "    \n",
    "#     return bsr_matrix((kernel_samples, (row_col_pairs[:, 0], row_col_pairs[:, 1])), shape=(l**2, l**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521eaea-fefe-42bb-9580-53be1376e060",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%file conv_matrix_sparse.py\n",
    "\n",
    "# from memory_profiler import profile\n",
    "import numpy as np\n",
    "from scipy.sparse import bsr_matrix, diags, dia_matrix, csr_matrix\n",
    "\n",
    "# Steps to map a 2d convolution kernel to a \"convolution\" matrix. \n",
    "# Note: this disregards padding of the convolution at edges of the matrix to be \"convolved\" with. This is essentially a diagonal matrix, where the 2d kernel\n",
    "#       is flattened, and each 1d \"slice\" is strided from one another by a separation of around \"convolution\" matrix width.\n",
    "# Note: this method assumes we can build up a subset of the full matrix (lets call it a \"submatrix\"), and use simply arithmetic to\n",
    "#       \"slide\" the submatrix diagonally to populate the full \"convolution\" matrix.\n",
    "# Note: The format for storing this matrix is the Block Compressed Row sparse matrix format:\n",
    "#       https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html\n",
    "\n",
    "# @profile\n",
    "def conv_matrix_sparse(l, kernel):\n",
    "    supp = kernel.shape[0]\n",
    "    half_supp = (supp - 1) // 2\n",
    "    diagonal_strides = np.linspace(-half_supp, half_supp, supp, dtype=np.intc)\n",
    "\n",
    "    submatrix_cols = np.zeros([], dtype=np.uintc)\n",
    "    submatrix_rows = np.zeros([], dtype=np.uintc)\n",
    "    submatrix_elements = np.zeros([], dtype=np.float32)\n",
    "\n",
    "    for k in range(supp):\n",
    "        # generate unpadded diagonal sparse matrix of kth kernel slice\n",
    "        k_bsr = dia_matrix.tocsr(diags(kernel[k], diagonal_strides, shape=(l, l)))\n",
    "\n",
    "        cols_for_rows = np.split(k_bsr.indices, k_bsr.indptr[1:-1]) # get col indices for entries in matrix\n",
    "        rows_for_cols = np.repeat(np.arange(l), [len(arr) for arr in cols_for_rows])\n",
    "        cols_for_rows = np.concatenate(cols_for_rows).ravel() + k * l # offset each diagonal\n",
    "\n",
    "        # Ideally use of pre-allocated memory of known dimensions is ideal... but okay for now\n",
    "        submatrix_cols = np.append(submatrix_cols, cols_for_rows)\n",
    "        submatrix_rows = np.append(submatrix_rows, rows_for_cols)\n",
    "        submatrix_elements = np.append(submatrix_elements, k_bsr.data)\n",
    "\n",
    "    matrix_cols = np.zeros([], dtype=np.uintc)\n",
    "    matrix_rows = np.zeros([], dtype=np.uintc)\n",
    "    matrix_elements = np.zeros([], dtype=np.float32)\n",
    "\n",
    "    # Now that we have the initial \"submatrix\" of diagonals, we can populate\n",
    "    # the sparse matrix using strided, truncated submatrices\n",
    "    for index, stride in enumerate(np.arange(-half_supp, -half_supp + l) * l):\n",
    "        strided_cols = submatrix_cols + stride\n",
    "        in_range_cols = np.where((strided_cols >= 0) & (strided_cols < l**2))\n",
    "        strided_rows = submatrix_rows + index * l\n",
    "        valid_elements = submatrix_elements\n",
    "\n",
    "        # This needs changing at some point, highly inefficient...\n",
    "        matrix_cols = np.append(matrix_cols, strided_cols[in_range_cols])\n",
    "        matrix_rows = np.append(matrix_rows, strided_rows[in_range_cols])\n",
    "        matrix_elements = np.append(matrix_elements, submatrix_elements[in_range_cols])\n",
    "\n",
    "    return csr_matrix((matrix_elements, (matrix_rows, matrix_cols)), shape=(l**2, l**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d80073-e7d6-456f-9184-2902da26f4ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from conv_matrix_sparse import conv_matrix_sparse\n",
    "\n",
    "# def gkern(l=5, sig=1.):\n",
    "#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "#     kernel = np.outer(gauss, gauss)\n",
    "#     return kernel / np.sum(kernel)\n",
    "\n",
    "# l = 50\n",
    "# # kernel = np.array([[0, -1,  0], [-1,  4, -1], [0, -1,  0]], dtype=np.float32)\n",
    "# # kernel = np.array([[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7], [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]], dtype=np.float32) * 1/273\n",
    "# kernel = gkern(9)\n",
    "\n",
    "# sparse = conv_matrix_sparse(l, kernel)\n",
    "# # show_sparse_image(sparse, \"Sparse Matrix (fast implementation)\")\n",
    "# print((sparse.data.nbytes + sparse.indptr.nbytes + sparse.indices.nbytes) / 10**6)\n",
    "\n",
    "#===============#\n",
    "# Testing\n",
    "#===============#\n",
    "\n",
    "# m = convolution_matrix_sparse(l, kernel)\n",
    "# show_sparse_image(sparse, \"Sparse Matrix (fast implementation)\")\n",
    "# show_sparse_image(m, \"Sparse Matrix (slow implementation)\")\n",
    "# show_sparse_image(sparse - m, \"Sparse Matrix (diff)\")\n",
    "\n",
    "# x_true = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "# show_image(x, \"X\")\n",
    "\n",
    "# scikit_convolved = normalise(convolve2d(x, kernel.reshape(supp, supp), mode=\"same\"))\n",
    "# show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "\n",
    "# x = x.reshape(1, x.shape[0]**2)\n",
    "# x = sparse @ x.T\n",
    "# x = x.reshape(l, l)\n",
    "        \n",
    "# show_image(normalise(x), \"Sharpened X\")\n",
    "# show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc190eb-c6f2-437e-abe7-a25c8bac9012",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### $L_{1}$ and $L_{\\infty}$ norms of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e55d4c-dc38-4f79-aaa2-7f93d3af1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(1, 10).reshape(3, 3)\n",
    "# print(x)\n",
    "\n",
    "# # Max absolute column sum of matrix\n",
    "# l_one = np.max(np.sum(np.absolute(x), axis=0))\n",
    "# print(l_one)\n",
    "\n",
    "# # Max absolute row sum of matrix\n",
    "# l_inf = np.max(np.sum(np.absolute(x), axis=1))\n",
    "# print(l_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c225f5c-69cd-4af8-ab84-9bc7d9b9f605",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Experimentation with different Scipy sparse matrix formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c30689-4d1d-4671-8e54-ab69c15e778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import numpy as np\n",
    "# from scipy.sparse import lil_matrix, dok_matrix, coo_matrix\n",
    "# from memory_profiler import profile\n",
    "\n",
    "# def generate_sparse_lil(l, k):\n",
    "#     # List of lists format\n",
    "#     m = lil_matrix((l**2, l**2), dtype=np.float32)\n",
    "#     d = np.arange(k**2)\n",
    "\n",
    "#     for r in range(l**2):\n",
    "        \n",
    "#         %time m[r, d] = d\n",
    "        \n",
    "#     return m\n",
    "    \n",
    "# def generate_sparse_dok(l, k):\n",
    "    \n",
    "#     m = dok_matrix((l**2, l**2), dtype=np.float32)\n",
    "    \n",
    "#     for r in range(l**2):\n",
    "#         for c in range(k**2):\n",
    "#             m[r, c] = 1.0\n",
    "    \n",
    "#     return m\n",
    "\n",
    "# def generate_sparse_coo(l, k):\n",
    "#     r = np.repeat(np.arange(l**2), k**2)\n",
    "#     print(r)\n",
    "#     c = np.tile(np.arange(k**2), l**2)\n",
    "#     print(c)\n",
    "#     v = np.tile(np.arange(k**2), l**2)\n",
    "#     print(v)\n",
    "#     m = coo_matrix((v, (r, c)), shape=(l**2, l**2), dtype=np.float32)\n",
    "#     return m\n",
    "    \n",
    "# def generate_sparse_diag(l, k):\n",
    "#     diagonals = np.arange(k)\n",
    "#     offsets = np.arange(k) - (k-1)//2\n",
    "#     return dia_matrix.tocsr(diags(diagonals, offsets, shape=(l**2, l**2)))\n",
    "    \n",
    "# l = 400\n",
    "# k = 50\n",
    "\n",
    "# m = generate_sparse_lil(l, k)\n",
    "# m = generate_sparse_dok(l, k)\n",
    "# m = generate_sparse_coo(l, k)\n",
    "# m = generate_sparse_diag(l, k)\n",
    "# show_sparse_image(m, \"Sparse Matrix (fast implementation)\")\n",
    "\n",
    "# Notes: have a play around with progressively building up a lil matrix/array over submatrix chunks, then convert to compressed format\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html\n",
    "# https://stackoverflow.com/questions/4565685/how-to-efficiently-add-sparse-matrices-in-python\n",
    "\n",
    "# Notes: alternatively have a look at the coo format, then convert compressed. Although this may suffer from repeated row/cols.\n",
    "# https://scipy-lectures.org/advanced/scipy_sparse/coo_matrix.html\n",
    "\n",
    "# Ideal: use parallel numba to generate sub matrices and then produce a coo spaee matrix from their concated row/col/elem arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec92a39-97d4-4124-9b72-882021a8b4ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Convolution of a sparse, padded, \"convolution\" matrix with an image vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e694d-50e7-415b-ac97-92137fe49ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def gkern(l=5, sig=1.):\n",
    "#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "#     kernel = np.outer(gauss, gauss)\n",
    "#     return kernel / np.sum(kernel)\n",
    "\n",
    "# # Convolution kernel\n",
    "# k_supp = 3\n",
    "# k_supp_half = (k_supp - 1) // 2 \n",
    "# gaussian = gkern(k_supp, 3.0)\n",
    "# # show_image(gaussian, \"Gaussian\")\n",
    "\n",
    "# # Sample image\n",
    "# l = 5\n",
    "# l_padded = l + k_supp - 1\n",
    "# x = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x, (l, l), anti_aliasing=True)\n",
    "# # show_image(x, \"X\")\n",
    "\n",
    "# # scikit_convolved = normalise(convolve2d(x, gaussian, mode=\"same\")) # use full to compare against the partially processed edges\n",
    "# # show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "\n",
    "# # \"Convolution\" matrix\n",
    "# gaussian = gaussian.flatten()\n",
    "# offsets = np.arange(k_supp**2)\n",
    "# conv_m = dia_matrix.tocsr(diags(gaussian, offsets, shape=(l**2, l**2)))\n",
    "# show_sparse_image(conv_m, \"Sparse Conv Matrix\")\n",
    "# print((conv_m.data.nbytes + conv_m.indptr.nbytes + conv_m.indices.nbytes) / 10**6)\n",
    "\n",
    "# # pad x to accomodate convolution\n",
    "# x = np.pad(x, k_supp_half)\n",
    "# print((x.size * x.itemsize) / 10**6)\n",
    "# # x = x.reshape(1, l**2)\n",
    "# # x = conv_m @ x.T\n",
    "# # x = x.reshape(l, l)\n",
    "        \n",
    "# show_image(normalise(x), \"Smoothed X\")\n",
    "# # show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")\n",
    "\n",
    "# # Ideal: might make sense to use a numba accelerated function which populates preallocated numpy arrays for row/col/element values\n",
    "# # then use those to create a coo(?) sparse matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824e39b-3538-450a-878a-3228d18e4118",
   "metadata": {},
   "source": [
    "### Investigating the use of scipy sparse block diagram matrix formations for conv/deci matrices\n",
    "See: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.block_diag.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9c00d-7392-4330-a5c2-ec16b2e28fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import block_diag\n",
    "\n",
    "l = 5\n",
    "m = dok_matrix((l**2, l**2), dtype=np.float32)\n",
    "\n",
    "for r in range(l):\n",
    "    for c in range(l):\n",
    "        m[r, c] = l\n",
    "\n",
    "print(m.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388326c-c90b-4367-9b48-4699d0bc4a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

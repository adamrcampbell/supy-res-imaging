{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51991948-7406-4f23-ac5a-97858510c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for memory usage profiling\n",
    "%load_ext memory_profiler\n",
    "# Needed for runtime profiling\n",
    "%load_ext line_profiler\n",
    "# Needed for static or interactive matplotlib plots\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.sparse import bsr_matrix\n",
    "\n",
    "from skimage import data, io, color\n",
    "from skimage.transform import resize\n",
    "\n",
    "from array import array\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "def show_image(image, title):\n",
    "    plt.imshow(image, cmap=plt.get_cmap(\"gray\"))\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def show_sparse_image(image, title):\n",
    "    plt.spy(image)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def normalise(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def linear_to_row_col(index, row_width):\n",
    "    return (index // row_width, index % row_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fb6a0-1932-428e-a19c-5ca060a89079",
   "metadata": {},
   "source": [
    "##### Decimation matrix (row major) - assumes only taking 4 neighbours and that $L = M*2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbe90ef-c36d-42a4-97d9-6cf48eb2ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 4\n",
    "# m = 2\n",
    "# d = l // m\n",
    "\n",
    "# d_matrix = np.zeros((m**2, l**2))\n",
    "\n",
    "# tile = np.repeat((1, 0, 1), (2, l - 2, 2)) # assuming taking 2 neighbours per dimension\n",
    "# t_len = tile.shape[0]\n",
    "\n",
    "# for p in np.arange(l//4):\n",
    "#     p_offset = p * l # 8\n",
    "#     for q in np.arange(m):\n",
    "#         d_matrix[q+ p_offset//2, q*d + p_offset*2 : q*d+t_len + p_offset*2] = tile # top-left quadrant\n",
    "#         r_offset = m**2 // 2\n",
    "#         c_offset = l**2 // 2\n",
    "#         d_matrix[q+r_offset + p_offset//2, q*d+c_offset + p_offset*2: q*d+t_len+c_offset + p_offset*2] = tile # bottom-right quadrant\n",
    "        \n",
    "# print(d_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa309fc-df94-43db-ba2b-4880e9fd692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(1, 65) # 1..64\n",
    "# print(x.reshape(8, 8))\n",
    "\n",
    "# y = np.matmul(d_matrix * 1/4, x)\n",
    "# print(y.reshape(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19690611-6387-4989-bfd9-054710062f70",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Decimation matrix - downsample matrix $l^2$ by integer factor $n$ (assumes $n$ is suitable factor of $l$ shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb71a3c6-5d6a-4704-bcd3-f05cdeb93dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decimation_matrix(original_dim, downsample_factor):\n",
    "    \n",
    "#     if original_dim % downsample_factor != 0:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} is not a valid factor of your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == original_dim:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} cannot be the same as your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == 1: # effectively, no downsampling\n",
    "#         return np.identity(original_dim**2)\n",
    "#     # Otherwise assumed you want to downsample by a valid factor of original_dim...\n",
    "    \n",
    "#     sampling_regions_per_dim = original_dim // downsample_factor\n",
    "#     samples_per_region_dim = downsample_factor\n",
    "#     # print(f\"Sampling regions per dimension: {sampling_regions_per_dim}\")\n",
    "#     deci = np.zeros((sampling_regions_per_dim**2, original_dim**2))\n",
    "#     # print(deci.shape)\n",
    "    \n",
    "#     # Generates linear x,y index strides for downsampling\n",
    "#     sample_stride_1D = np.arange(0, original_dim, downsample_factor)\n",
    "#     # print(sample_stride_1D)\n",
    "#     mesh = np.array(np.meshgrid(sample_stride_1D, sample_stride_1D))\n",
    "#     sample_strides_2D = mesh.T.reshape(-1, 2)\n",
    "#     # print(sample_strides_2D)\n",
    "  \n",
    "#     neighbour_strides_1D = np.arange(samples_per_region_dim)\n",
    "#     neighbour_mesh = np.array(np.meshgrid(neighbour_strides_1D, neighbour_strides_1D))\n",
    "\n",
    "#     for index in np.arange(sample_strides_2D.shape[0]):\n",
    "#         neighbour_coords = neighbour_mesh.T.reshape(-1, 2) + sample_strides_2D[index] # generates (row, col) index pair for the nxn neighbours of each sampling point in sample_strides_2D\n",
    "#         neighbour_coords[:, 0] *= original_dim # scale y coord by high-resolution image dim to enable row striding (due to column-vector matrix flattening)\n",
    "#         neighbour_coords = np.sum(neighbour_coords, axis=1) # combine x and y coord into single array index\n",
    "#         deci[index, neighbour_coords] = 1.0\n",
    "        \n",
    "#     return deci\n",
    "    \n",
    "# # Testing of new decimation matrix routine\n",
    "# l = np.arange(9**2)\n",
    "# print(l.reshape(9, 9))\n",
    "# d = decimation_matrix(9, 3)\n",
    "# show_plot(d)\n",
    "# m = d @ l\n",
    "# print(m.shape)\n",
    "# print(m.reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcb722-f9ee-4c31-ab2d-7d2ff07e3712",
   "metadata": {},
   "source": [
    "Decimation matrix using the [Block Sparse Row (BSR) matrix format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy-sparse-bsr-matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5485d3ab-dc76-4efa-9c9c-cd104764d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decimation_matrix(original_dim, downsample_factor):\n",
    "    \n",
    "#     if original_dim % downsample_factor != 0:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} is not a valid factor of your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == original_dim:\n",
    "#         raise ValueError(f\"Downsample factor {downsample_factor} cannot be the same as your matrix dimension {original_dim}.\")\n",
    "#     if downsample_factor == 1: # effectively, no downsampling\n",
    "#         return np.identity(original_dim**2)\n",
    "#     # Otherwise assumed you want to downsample by a valid factor of original_dim...\n",
    "    \n",
    "#     sampling_regions_per_dim = original_dim // downsample_factor\n",
    "#     samples_per_region_dim = downsample_factor\n",
    "#     # print(f\"Sampling regions per dimension: {sampling_regions_per_dim}\")\n",
    "#     # print(f\"Samples per dimension: {samples_per_region_dim}\")\n",
    "#     non_zero_entries = sampling_regions_per_dim**2 * samples_per_region_dim**2\n",
    "#     # print(f\"Non-zero entries: {non_zero_entries}\")\n",
    "    \n",
    "#     rows = np.zeros(non_zero_entries, dtype=np.uintc)   # stores row indices for non-zero compressed sparse matrix entries\n",
    "#     cols = np.zeros(non_zero_entries, dtype=np.uintc)   # stores col indices for non-zero compressed sparse matrix entries\n",
    "#     vals = np.ones(non_zero_entries, dtype=np.float32)  # stores element value at [row, col] for non-zero entries\n",
    "    \n",
    "#     # Generates linear x,y index strides for downsampling\n",
    "#     sample_stride_1D = np.arange(0, original_dim, downsample_factor)\n",
    "#     # print(sample_stride_1D)\n",
    "#     mesh = np.array(np.meshgrid(sample_stride_1D, sample_stride_1D))\n",
    "#     sample_strides_2D = mesh.T.reshape(-1, 2)\n",
    "  \n",
    "#     neighbour_strides_1D = np.arange(samples_per_region_dim)\n",
    "#     neighbour_mesh = np.array(np.meshgrid(neighbour_strides_1D, neighbour_strides_1D))\n",
    "\n",
    "#     for index in np.arange(sample_strides_2D.shape[0]):\n",
    "#         neighbour_coords = neighbour_mesh.T.reshape(-1, 2) + sample_strides_2D[index] # generates (row, col) index pair for the nxn neighbours of each sampling point in sample_strides_2D\n",
    "#         neighbour_coords[:, 0] *= original_dim # scale y coord by high-resolution image dim to enable row striding (due to column-vector matrix flattening)\n",
    "#         neighbour_coords = np.sum(neighbour_coords, axis=1) # combine x and y coord into single array index\n",
    "#         rows[index * neighbour_coords.shape[0] : (index + 1) * neighbour_coords.shape[0]] = index\n",
    "#         cols[index * neighbour_coords.shape[0] : (index + 1) * neighbour_coords.shape[0]] = neighbour_coords\n",
    "        \n",
    "#     return bsr_matrix((vals, (rows, cols)))\n",
    "    \n",
    "# # Testing of new decimation matrix routine\n",
    "# l_dim = 8\n",
    "# deci_factor = 4\n",
    "\n",
    "# l = np.arange(l_dim**2)\n",
    "# print(l.reshape(l_dim, l_dim))\n",
    "# d = decimation_matrix(l_dim, deci_factor)\n",
    "# print(type(d))\n",
    "# print((d.data.nbytes + d.indptr.nbytes + d.indices.nbytes) / 10**6)\n",
    "# # print(d)\n",
    "# # show_image(d, \"D\")\n",
    "# m = d @ l\n",
    "# print(m.shape)\n",
    "# print(m.reshape(l_dim//deci_factor, l_dim//deci_factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970d022-cf44-4a74-a1f5-5829da2507da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Sharpening matrix (padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8135b9-0a70-4508-a23f-7637ee572d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_true = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x_true, (100, 100), anti_aliasing=True)\n",
    "# show_plot(x)\n",
    "\n",
    "# laplace_deblur = np.array([[0, -1,  0], [-1,  4, -1], [0, -1,  0]], dtype=np.float32)\n",
    "# scikit_convolved = normalise(convolve2d(x, laplace_deblur, mode=\"same\"))\n",
    "# show_plot(scikit_convolved)\n",
    "\n",
    "# l = x.shape[0]\n",
    "# laplacian = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=np.float32)\n",
    "# laplacian_dim = laplacian.shape[0]\n",
    "# padding = laplacian_dim - 1 # s_matrix padding for out of bounds convolution\n",
    "# laplacian = laplacian.flatten()\n",
    "# strided_laplacian = np.insert(laplacian, laplacian_dim, np.repeat(0, l-1))\n",
    "# strided_laplacian = np.insert(strided_laplacian, laplacian_dim*2+l-1, np.repeat(0, l-1))\n",
    "# s_matrix = np.zeros(((l+padding)**2, (l+padding)**2), dtype=np.float32)\n",
    "\n",
    "# for sr in np.arange(l):\n",
    "#     for r in np.arange(l):\n",
    "#         row_offset = (sr*l)+(l+padding+padding//2)+(padding*sr)\n",
    "#         col_offset = sr*(l+padding)+r\n",
    "#         s_matrix[row_offset+r, col_offset:col_offset+strided_laplacian.shape[0]] = strided_laplacian\n",
    "\n",
    "# show_plot(s_matrix)\n",
    "        \n",
    "# x_padded = np.pad(x, 1)\n",
    "# x_padded = x_padded.reshape(1, x_padded.shape[0]**2)\n",
    "# x_padded = np.matmul(s_matrix, x_padded.T)\n",
    "# x_padded = x_padded.reshape(102, 102)[1:101, 1:101]\n",
    "        \n",
    "# show_plot(normalise(x_padded))\n",
    "# show_plot(scikit_convolved - normalise(x_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a4853-e2af-4d4c-8a04-da18eee98ff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Convolution matrix (no padding, sharpening example) using the [Block Sparse Row (BSR) matrix format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy-sparse-bsr-matrix)\n",
    "##### (Note: only works for small samples... it is too much of a memory hog...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e08f2b0-91be-4b69-94d8-572d77d3ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convolution_matrix(l, kernel):\n",
    "#     conv = np.zeros((l**2, l**2), dtype=np.float32)\n",
    "#     full_supp = kernel.shape[0] # assumed square\n",
    "#     half_supp = (full_supp - 1) // 2\n",
    "\n",
    "#     for conv_row in np.arange(l**2):\n",
    "\n",
    "#         row, col = (conv_row // l, conv_row % l)\n",
    "\n",
    "#         for k_row in np.arange(-(half_supp), half_supp + 1):\n",
    "#             # map \"kernel row\" to rows in conv\n",
    "#             mapped_row = row + k_row\n",
    "#             # ignore any out of bounds rows\n",
    "#             if mapped_row >= 0 and mapped_row < l:\n",
    "#                 linear_col = col - half_supp\n",
    "#                 # truncate negative columns\n",
    "#                 mapped_col_start = max(linear_col, 0)\n",
    "#                 # truncate columns which exceed the l dimension\n",
    "#                 mapped_col_end = min(linear_col + full_supp, l)\n",
    "#                 # left trimming for kernels when overlapping out of bounds region in conv (col < 0)\n",
    "#                 left = np.absolute(col - half_supp) if linear_col < 0 else 0\n",
    "#                 # right trimming for kernels when overlapping out of bounds region in conv (col >= l)\n",
    "#                 right = linear_col + full_supp - l if linear_col + full_supp >= l else 0 \n",
    "#                 # copy over kernel row for current k_row, possibly including trimming for out of bounds coordinates\n",
    "#                 conv[conv_row][mapped_row * l + mapped_col_start : mapped_row * l + mapped_col_end] = kernel[k_row + half_supp][left: left + full_supp - right]\n",
    "#     return conv\n",
    "\n",
    "# l = 300\n",
    "# x_true = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "# # show_image(x, \"X\")\n",
    "\n",
    "# laplace = np.array([[1, -1,  1], [-1,  4, -1], [1, -1,  1]], dtype=np.float32)\n",
    "# # laplace = np.array([[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7], [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]], dtype=np.float32) * 1/273\n",
    "# full_supp = laplace.shape[0] # assumed square\n",
    "# half_supp = (full_supp - 1) // 2\n",
    "# kernel_samples = full_supp**2\n",
    "\n",
    "# non_zero_entries = full_supp**2 * l**2\n",
    "# # print(f\"Total non-zero entries: {non_zero_entries}\")\n",
    "# rows = np.zeros(non_zero_entries, dtype=np.uintc)\n",
    "# cols = np.zeros(non_zero_entries, dtype=np.intc)\n",
    "# vals = np.zeros(non_zero_entries, dtype=np.float32)\n",
    "\n",
    "# # for each flattened \"convolution\" row in matrix\n",
    "# for m_row in np.arange(l**2):\n",
    "    \n",
    "#     # map flattened m_row to 2d row/col  \n",
    "#     row, col = (m_row // l, m_row % l)\n",
    "#     # print(f\"M_row {m_row} maps to row/col {row}, {col}\")\n",
    "    \n",
    "#     # map kernel to neighbouring indices of row/col, from centre of kernel\n",
    "#     neighbour_rows =  np.arange(-(half_supp), half_supp+1) + row\n",
    "#     neighbour_cols = np.arange(-(half_supp), half_supp+1) + col\n",
    "#     mesh = np.array(np.meshgrid(neighbour_rows, neighbour_cols))\n",
    "#     neighbour_indices = mesh.T.reshape(-1, 2)\n",
    "    \n",
    "#     # zero out in kernel, any neighbours which have negative index or greater than l\n",
    "#     bad_rows = np.concatenate((np.where(neighbour_indices[:, 0] < 0)[0], np.where(neighbour_indices[:, 0] >= l)[0]))\n",
    "#     bad_cols = np.concatenate((np.where(neighbour_indices[:, 1] < 0)[0], np.where(neighbour_indices[:, 1] >= l)[0]))\n",
    "#     # get a set of distinct neighbours to be zeroed out (in case of duplicate entries where a bad row is also a bad column)\n",
    "#     bad_neighbours = np.unique(np.concatenate((bad_rows, bad_cols)))\n",
    "#     # print(bad_neighbours)\n",
    "    \n",
    "#     kernel = laplace.flatten()\n",
    "#     kernel[bad_neighbours] = 0.0\n",
    "    \n",
    "#     start = m_row * full_supp**2\n",
    "#     end = (m_row + 1) * full_supp**2\n",
    "#     col_strides = np.repeat((np.arange(-half_supp, half_supp + 1)), (np.repeat(full_supp, full_supp))) * (l - full_supp)\n",
    "#     # populating row indices and flattened kernel slices\n",
    "#     rows[start:end] = m_row\n",
    "#     cols[start:end] = (np.arange(m_row, m_row + full_supp**2) - full_supp**2 // 2 + col_strides)\n",
    "#     vals[start:end] = kernel\n",
    "    \n",
    "# # strip away any entries in rows/cols/vals where cols < 0, cols >= l**2, or where val is zero\n",
    "# out_of_bounds_or_zero = np.concatenate((np.where(cols < 0), np.where(cols >= l**2), np.where(vals == 0.0)), axis=None)\n",
    "# rows = np.delete(rows, out_of_bounds_or_zero)\n",
    "# cols = np.delete(cols, out_of_bounds_or_zero)\n",
    "# vals = np.delete(vals, out_of_bounds_or_zero)\n",
    "\n",
    "# # original_method = convolution_matrix(l, laplace.reshape(full_supp, full_supp))\n",
    "# # # print((original_method.size * original_method.itemsize) / 10**6)\n",
    "# # show_image(original_method, \"Original Sharpening matrix\")\n",
    "\n",
    "# conv_matrix = bsr_matrix((vals, (rows, cols)))\n",
    "# # print((conv_matrix.data.nbytes + conv_matrix.indptr.nbytes + conv_matrix.indices.nbytes) / 10**6)\n",
    "# show_image(conv_matrix.todense(), \"Sharpening matrix\")\n",
    "\n",
    "# scikit_convolved = normalise(convolve2d(x, laplace.reshape(full_supp, full_supp), mode=\"same\"))\n",
    "# show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "\n",
    "# x = x.reshape(1, x.shape[0]**2)\n",
    "# x = conv_matrix.todense() @ x.T\n",
    "# # # x = original_method @ x.T\n",
    "# x = x.reshape(l, l)\n",
    "        \n",
    "# show_image(normalise(x), \"Sharpened X\")\n",
    "# show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a454ed-a276-4ab1-a0cf-9d73a5fead66",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Convolution matrix (no padding, sharpening example) using a dictionary (for efficiency?) and the [Block Sparse Row (BSR) matrix format](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html#scipy-sparse-bsr-matrix)\n",
    "*The assumption is that I can maintain a top-level dictionary, where the key = the convolution kernel sample, and the value is a secondary dictionary, where the key-value pair is the row and column index of said kernel sample. From there, I should in theory be able to generate appropriately sized row/col/sample numpy arrays only containing valid entries in the convolution matrix, built using the CSR or BSR format...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d227716-e309-4ec5-8f6b-3a459b94c0de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conv_matrix_sparse.py\n"
     ]
    }
   ],
   "source": [
    "%%file conv_matrix_sparse.py\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import bsr_matrix\n",
    "\n",
    "def convolution_matrix_sparse(l, kernel):\n",
    "    \n",
    "    # Allocate a key-value pair for each distinct kernel sample (key) to an empty list (value) \n",
    "    pixel_to_row_col_dict = {val : [] for val in np.unique(kernel)}\n",
    "    full_supp = kernel.shape[0] # assumed square\n",
    "    half_supp = (full_supp - 1) // 2\n",
    "    \n",
    "    kernel = kernel.flatten()\n",
    "    neighbour_strides = np.arange(-(half_supp), half_supp+1)\n",
    "    \n",
    "    for m_row in np.arange(l**2):\n",
    "        \n",
    "        # map flattened m_row to 2d row/col  \n",
    "        row, col = (m_row // l, m_row % l)\n",
    "        # print(f\"M_row {m_row} maps to row/col {row}, {col}\")\n",
    "        \n",
    "        neighbour_rows = neighbour_strides + row\n",
    "        neighbour_cols = neighbour_strides + col\n",
    "        \n",
    "        # map kernel to neighbouring indices of row/col, from centre of kernel\n",
    "        meshgrid = np.meshgrid(neighbour_rows, neighbour_cols, copy=False)\n",
    "        mesh = np.array(meshgrid)\n",
    "        neighbour_indices = mesh.T.reshape(-1, 2)\n",
    "        \n",
    "        # zero out in kernel, any neighbours which have negative index or greater than l\n",
    "        bad_rows = np.concatenate((np.where(neighbour_indices[:, 0] < 0)[0], np.where(neighbour_indices[:, 0] >= l)[0]))\n",
    "        bad_cols = np.concatenate((np.where(neighbour_indices[:, 1] < 0)[0], np.where(neighbour_indices[:, 1] >= l)[0]))\n",
    "        # get a set of distinct neighbours to be zeroed out (in case of duplicate entries where a bad row is also a bad column)\n",
    "        bad_neighbours = np.unique(np.concatenate((bad_rows, bad_cols)))\n",
    "        # print(f\"Bad neighbours: {bad_neighbours}\")\n",
    "\n",
    "        modified_kernel = np.copy(kernel)\n",
    "        # print(f\"Original kernel: {modified_kernel}\")\n",
    "        modified_kernel = np.delete(modified_kernel, bad_neighbours)\n",
    "        # print(f\"Modified kernel: {modified_kernel}\")\n",
    "        col_strides = np.repeat(neighbour_strides, (np.repeat(full_supp, full_supp))) * (l - full_supp)\n",
    "        # print(f\"Col Strides: {col_strides}\")\n",
    "        cols = np.delete((np.arange(m_row, m_row + full_supp**2) - full_supp**2 // 2 + col_strides), bad_neighbours)\n",
    "        \n",
    "        # print(f\"Column vals: {cols}\")\n",
    "        for index, entry in enumerate(modified_kernel):\n",
    "            pixel_to_row_col_dict[entry].append((m_row, cols[index]))\n",
    "        \n",
    "    entries = sum(len(v) for v in pixel_to_row_col_dict.values())\n",
    "    # print(entries)\n",
    "\n",
    "    row_col_pairs = np.zeros((entries, 2), dtype=np.uintc)\n",
    "    kernel_samples = np.zeros(entries, dtype=np.float32)\n",
    "    stride = 0\n",
    "    for k, v in pixel_to_row_col_dict.items():\n",
    "\n",
    "        if not v: # ignore pixels with no entries\n",
    "            continue\n",
    "\n",
    "        multiplier = len(v)\n",
    "        # print(multiplier)\n",
    "        kernel_samples[stride : stride + multiplier] = k\n",
    "        row_col_pairs[stride : stride + multiplier] = v\n",
    "        stride += multiplier\n",
    "    \n",
    "    return bsr_matrix((kernel_samples, (row_col_pairs[:, 0], row_col_pairs[:, 1])), shape=(l**2, l**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0adf83-d48c-46c5-927f-59e58602be36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.008398 s\n",
       "File: /supy_res/notebooks/conv_matrix_sparse.py\n",
       "Function: convolution_matrix_sparse at line 5\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     5                                           def convolution_matrix_sparse(l, kernel):\n",
       "     6                                               \n",
       "     7                                               # Allocate a key-value pair for each distinct kernel sample (key) to an empty list (value) \n",
       "     8         1         88.0     88.0      1.0      pixel_to_row_col_dict = {val : [] for val in np.unique(kernel)}\n",
       "     9         1          2.0      2.0      0.0      full_supp = kernel.shape[0] # assumed square\n",
       "    10         1          1.0      1.0      0.0      half_supp = (full_supp - 1) // 2\n",
       "    11                                               \n",
       "    12         1          2.0      2.0      0.0      kernel = kernel.flatten()\n",
       "    13         1          6.0      6.0      0.1      neighbour_strides = np.arange(-(half_supp), half_supp+1)\n",
       "    14                                               \n",
       "    15        26         58.0      2.2      0.7      for m_row in np.arange(l**2):\n",
       "    16                                                   \n",
       "    17                                                   # map flattened m_row to 2d row/col  \n",
       "    18        25         54.0      2.2      0.6          row, col = (m_row // l, m_row % l)\n",
       "    19                                                   # print(f\"M_row {m_row} maps to row/col {row}, {col}\")\n",
       "    20                                                   \n",
       "    21        25        114.0      4.6      1.4          neighbour_rows = neighbour_strides + row\n",
       "    22        25         74.0      3.0      0.9          neighbour_cols = neighbour_strides + col\n",
       "    23                                                   \n",
       "    24                                                   # map kernel to neighbouring indices of row/col, from centre of kernel\n",
       "    25        25       1796.0     71.8     21.4          meshgrid = np.meshgrid(neighbour_rows, neighbour_cols, copy=False)\n",
       "    26        25        145.0      5.8      1.7          mesh = np.array(meshgrid)\n",
       "    27        25         80.0      3.2      1.0          neighbour_indices = mesh.T.reshape(-1, 2)\n",
       "    28                                                   \n",
       "    29                                                   # zero out in kernel, any neighbours which have negative index or greater than l\n",
       "    30        25        450.0     18.0      5.4          bad_rows = np.concatenate((np.where(neighbour_indices[:, 0] < 0)[0], np.where(neighbour_indices[:, 0] >= l)[0]))\n",
       "    31        25        346.0     13.8      4.1          bad_cols = np.concatenate((np.where(neighbour_indices[:, 1] < 0)[0], np.where(neighbour_indices[:, 1] >= l)[0]))\n",
       "    32                                                   # get a set of distinct neighbours to be zeroed out (in case of duplicate entries where a bad row is also a bad column)\n",
       "    33        25        764.0     30.6      9.1          bad_neighbours = np.unique(np.concatenate((bad_rows, bad_cols)))\n",
       "    34                                                   # print(f\"Bad neighbours: {bad_neighbours}\")\n",
       "    35                                           \n",
       "    36        25        125.0      5.0      1.5          modified_kernel = np.copy(kernel)\n",
       "    37                                                   # print(f\"Original kernel: {modified_kernel}\")\n",
       "    38        25        686.0     27.4      8.2          modified_kernel = np.delete(modified_kernel, bad_neighbours)\n",
       "    39                                                   # print(f\"Modified kernel: {modified_kernel}\")\n",
       "    40        25        488.0     19.5      5.8          col_strides = np.repeat(neighbour_strides, (np.repeat(full_supp, full_supp))) * (l - full_supp)\n",
       "    41                                                   # print(f\"Col Strides: {col_strides}\")\n",
       "    42        25        823.0     32.9      9.8          cols = np.delete((np.arange(m_row, m_row + full_supp**2) - full_supp**2 // 2 + col_strides), bad_neighbours)\n",
       "    43                                                   \n",
       "    44                                                   # print(f\"Column vals: {cols}\")\n",
       "    45       386        478.0      1.2      5.7          for index, entry in enumerate(modified_kernel):\n",
       "    46       361        544.0      1.5      6.5              pixel_to_row_col_dict[entry].append((m_row, cols[index]))\n",
       "    47                                                   \n",
       "    48         1          5.0      5.0      0.1      entries = sum(len(v) for v in pixel_to_row_col_dict.values())\n",
       "    49                                               # print(entries)\n",
       "    50                                           \n",
       "    51         1          3.0      3.0      0.0      row_col_pairs = np.zeros((entries, 2), dtype=np.uintc)\n",
       "    52         1          3.0      3.0      0.0      kernel_samples = np.zeros(entries, dtype=np.float32)\n",
       "    53         1          1.0      1.0      0.0      stride = 0\n",
       "    54         7          5.0      0.7      0.1      for k, v in pixel_to_row_col_dict.items():\n",
       "    55                                           \n",
       "    56         6          6.0      1.0      0.1          if not v: # ignore pixels with no entries\n",
       "    57                                                       continue\n",
       "    58                                           \n",
       "    59         6          6.0      1.0      0.1          multiplier = len(v)\n",
       "    60                                                   # print(multiplier)\n",
       "    61         6         11.0      1.8      0.1          kernel_samples[stride : stride + multiplier] = k\n",
       "    62         6        217.0     36.2      2.6          row_col_pairs[stride : stride + multiplier] = v\n",
       "    63         6          5.0      0.8      0.1          stride += multiplier\n",
       "    64                                               \n",
       "    65         1       1012.0   1012.0     12.1      return bsr_matrix((kernel_samples, (row_col_pairs[:, 0], row_col_pairs[:, 1])), shape=(l**2, l**2))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from conv_matrix_sparse import convolution_matrix_sparse\n",
    "\n",
    "l = 5\n",
    "# x_true = color.rgb2gray(data.astronaut())\n",
    "# x = resize(x_true, (l, l), anti_aliasing=True)\n",
    "# show_image(x, \"X\")\n",
    "\n",
    "# kernel = np.array([[0, -1,  0], [-1,  4, -1], [0, -1,  0]], dtype=np.float32) # laplacian sharpening\n",
    "kernel = np.array([[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7], [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]], dtype=np.float32) * 1/273\n",
    "# kernel = np.arange(49**2, dtype=np.float32).reshape(49, 49)\n",
    "\n",
    "# For getting a breakdown of memory usage\n",
    "# %mprun -f convolution_matrix_sparse matrix=convolution_matrix_sparse(l, kernel)\n",
    "\n",
    "# For getting a breakdown of execution time\n",
    "%lprun -f convolution_matrix_sparse matrix=convolution_matrix_sparse(l, kernel)\n",
    "\n",
    "# print((matrix.data.nbytes + matrix.indptr.nbytes + matrix.indices.nbytes) / 10**6)\n",
    "# show_sparse_image(matrix, \"Sparse Matrix\")\n",
    "# show_image(matrix.todense(), \"Dense Image of Sparse Matrix\")\n",
    "\n",
    "# scikit_convolved = normalise(convolve2d(x, kernel, mode=\"same\"))\n",
    "# show_image(scikit_convolved, \"Scikit Convolved\")\n",
    "\n",
    "# x = x.reshape(1, x.shape[0]**2)\n",
    "# x = matrix @ x.T\n",
    "# x = x.reshape(l, l)\n",
    "        \n",
    "# show_image(normalise(x), \"Sharpened X\")\n",
    "# show_image(np.absolute(scikit_convolved - normalise(x)), \"Abs Diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc190eb-c6f2-437e-abe7-a25c8bac9012",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### $L_{1}$ and $L_{\\infty}$ norms of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e55d4c-dc38-4f79-aaa2-7f93d3af1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(1, 10).reshape(3, 3)\n",
    "# print(x)\n",
    "\n",
    "# # Max absolute column sum of matrix\n",
    "# l_one = np.max(np.sum(np.absolute(x), axis=0))\n",
    "# print(l_one)\n",
    "\n",
    "# # Max absolute row sum of matrix\n",
    "# l_inf = np.max(np.sum(np.absolute(x), axis=1))\n",
    "# print(l_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c225f5c-69cd-4af8-ab84-9bc7d9b9f605",
   "metadata": {},
   "source": [
    "#### Sparse matrix generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "979ccdca-8014-4c12-86ad-1169ee8056c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row strides: [-5.  0.  5.]\n",
      "Col strides: [-1.  0.  1.]\n",
      "offsets: [-6. -5. -4. -1.  0.  1.  4.  5.  6.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:31\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_construct.py:169\u001b[0m, in \u001b[0;36mdiags\u001b[0;34m(diagonals, offsets, shape, format, dtype)\u001b[0m\n\u001b[1;32m    166\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mmin\u001b[39m(m \u001b[38;5;241m+\u001b[39m offset, n \u001b[38;5;241m-\u001b[39m offset) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, offset)\n\u001b[1;32m    167\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m offset \u001b[38;5;129;01min\u001b[39;00m offsets])\n\u001b[1;32m    168\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, M)\n\u001b[0;32m--> 169\u001b[0m data_arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(m, n)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, diagonal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(diagonals):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from scipy.sparse import diags\n",
    "\n",
    "# n = 100\n",
    "# stride = 10\n",
    "# ex = np.ones(n)\n",
    "# data = np.array([ex, 2 * ex, ex])\n",
    "# print(data.shape)\n",
    "# offsets = np.array([-stride, 0, stride])\n",
    "# matrix = dia_matrix((data, offsets), shape=(n, n))\n",
    "\n",
    "l = 5\n",
    "supp = 3\n",
    "half_supp = (supp - 1) // 2\n",
    "\n",
    "kernel = np.array([[0, -1,  0], [-1,  4, -1], [0, -1,  0]], dtype=np.float32).flatten()\n",
    "# offsets = np.arange(-(4), 4+1)\n",
    "# print(offsets)\n",
    "\n",
    "row_strides = np.linspace(-l, l, supp)\n",
    "print(f\"Row strides: {row_strides}\")\n",
    "col_strides = np.linspace(-half_supp, half_supp, supp)\n",
    "print(f\"Col strides: {col_strides}\")\n",
    "# strides = np.repeat(row_strides, 3)\n",
    "offsets = np.repeat(row_strides, 3) + np.tile(col_strides, 3)\n",
    "print(f\"offsets: {offsets}\")\n",
    "\n",
    "# neighbour_strides = np.arange(-(half_supp), half_supp+1)\n",
    "# print(f\"neighbour_strides: {neighbour_strides}\")\n",
    "# strides = np.repeat(neighbour_strides, (np.repeat(supp, supp))) * (l - supp)\n",
    "# print(f\"strides: {strides}\")\n",
    "matrix = diags(kernel, offsets, shape=(l**2, l**2))\n",
    "\n",
    "# offsets = np.array([-stride, 0, stride])\n",
    "# matrix = dia_matrix((kernel, offsets), shape=(l**2, l**2))\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c30689-4d1d-4671-8e54-ab69c15e778e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
